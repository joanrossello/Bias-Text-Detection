{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"vwBKa0t-fisM"},"outputs":[],"source":["# choose dataset from 'NPOV', 'WNC', 'CrowS-Pairs', 'Stereo', 'Mixed'\n","dataset = 'Mixed'"]},{"cell_type":"markdown","metadata":{"id":"mP0P1_WTBRwZ"},"source":["# Setting up"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23662,"status":"ok","timestamp":1663328887921,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"},"user_tz":-60},"id":"SI_13tD70-ZQ","outputId":"204c7729-7ff1-4fdc-b427-31f6f2240c92"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12837,"status":"ok","timestamp":1663328900745,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"},"user_tz":-60},"id":"dxvoHuV7BCpA","outputId":"19eee5bc-32d4-45a6-b6b7-e3e494854115"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.22.0-py3-none-any.whl (4.9 MB)\n","\u001b[K     |████████████████████████████████| 4.9 MB 13.0 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting huggingface-hub<1.0,>=0.9.0\n","  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n","\u001b[K     |████████████████████████████████| 120 kB 61.7 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 56.1 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.22.0\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5710,"status":"ok","timestamp":1663328906444,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"},"user_tz":-60},"id":"5pUANSXcucdX","outputId":"c3bdfb72-4780-4daf-b39f-cbba789c0d99"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting bcolz-zipline\n","  Downloading bcolz_zipline-1.2.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 15.7 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bcolz-zipline) (1.21.6)\n","Installing collected packages: bcolz-zipline\n","Successfully installed bcolz-zipline-1.2.4\n"]}],"source":["!pip install bcolz-zipline"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["8197e2178b6f42498738c8626364043d","b175c0a4d63f42b79405e8488818231b","790fdcccc3834434bb94f55f67dbc4d6","eeca3ea230224bf49144ac77a4527cdb","b672e8d3053b4968ac59f3328ed462f0","603f4da89d274aa68b96c78bac9929c5","2f5ee401a1f64caf86bf0769b858508e","0235408599884559b7e988a7771f2793","5f716b0c436344d4a860cc69221e5401","2bac1637838a436ca568dcddc9cb3b77","a0d6a9f89ea6428e81ef9c073a8c80ba"]},"executionInfo":{"elapsed":34867,"status":"ok","timestamp":1663328941300,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"},"user_tz":-60},"id":"RzoL0hO1t0j9","outputId":"028ad97d-a694-4fcc-9f20-16ca43b0676d"},"outputs":[{"output_type":"stream","name":"stderr","text":["The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"]},{"output_type":"stream","name":"stdout","text":["Moving 0 files to the new cache system\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8197e2178b6f42498738c8626364043d"}},"metadata":{}}],"source":["import torch\n","import torch.nn as nn\n","import pandas as pd\n","import numpy as np\n","import shutil\n","import sys\n","from transformers import BloomTokenizerFast, BloomForSequenceClassification\n","from transformers import BertTokenizer, BertModel, BertTokenizerFast\n","\n","import nltk\n","from nltk.parse.stanford import StanfordDependencyParser\n","\n","import sys; sys.path.append('.')\n","\n","import spacy\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","import bcolz\n","\n","# Evaluation\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","import seaborn as sns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DjK_tPCoBQjd"},"outputs":[],"source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"]},{"cell_type":"markdown","metadata":{"id":"AlX3tF90Mx2-"},"source":["# Pickle functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7VOfsYPRNCap"},"outputs":[],"source":["import os\n","import pickle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9a9BYOc0MwkN"},"outputs":[],"source":["def load_pickle(filename):\n","    completeName = os.path.join(\"/content/drive/MyDrive/Colab Notebooks/Amplifi Project/Data/Processed Datasets/\",\\\n","                                filename)\n","    with open(completeName, 'rb') as pkl_file:\n","        data = pickle.load(pkl_file)\n","    return data\n","\n","def save_as_pickle(filename, data):\n","    completeName = os.path.join(\"/content/drive/MyDrive/Colab Notebooks/Amplifi Project/Data/Processed Datasets/\",\\\n","                                filename)\n","    with open(completeName, 'wb') as output:\n","        pickle.dump(data, output)"]},{"cell_type":"markdown","metadata":{"id":"7lAASlTuBVCu"},"source":["# TAGS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i-2XQ5f0t6uz"},"outputs":[],"source":["# Dependency parser: https://spacy.io/api/dependencyparser\n","# https://www.upgrad.com/blog/dependency-parsing-in-nlp/ \n","RELATIONS = ['<PAD>',\n","    'ROOT', 'acl', 'acomp', 'advcl', 'advmod', 'agent', 'amod', 'appos', \n","    'aux', 'auxpass', 'case', 'cc', 'ccomp', 'compound', 'conj', 'csubj', \n","    'dative', 'dep', 'det', 'dobj', 'expl', 'intj', 'mark', 'meta', 'neg',\n","    'nmod', 'npadvmod', 'nsubj', 'nsubjpass', 'nummod', 'oprd', 'parataxis',\n","    'pcomp', 'pobj', 'poss', 'preconj', 'predet', 'prep', 'prt', 'punct',\n","    'quantmod', 'relcl', 'xcomp', 'attr', 'csubjpass',\n","    '<UNK>'\n","]\n","REL2ID = {x: i for i, x in enumerate(RELATIONS)}\n","\n","# Part-Of-Speech tagging: https://spacy.io/usage/linguistic-features#pos-tagging \n","POS_TAGS = ['<PAD>',\n","    'ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'CONJ', 'DET', 'EOL',\n","    'IDS', 'INTJ', 'NAMES', 'NOUN', 'NO_TAG', 'NUM', 'PART',\n","    'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SPACE', 'SYM', 'VERB', 'X',\n","    '<UNK>'\n","]\n","POS2ID = {x: i for i, x in enumerate(POS_TAGS)} "]},{"cell_type":"markdown","metadata":{"id":"EGk80wOeBXja"},"source":["# Featurizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BAuv3HAShM3a"},"outputs":[],"source":["class Featurizer:\n","\n","    def __init__(self, tok2id={}, pad_id=0, lexicon_feature_bits=1):\n","        self.tok2id = tok2id\n","        self.id2tok = {x: tok for tok, x in tok2id.items()}\n","        self.pad_id = pad_id\n","\n","        self.pos2id = POS2ID\n","        self.rel2id = REL2ID\n","\n","        self.lexicons = {\n","            'assertives': self.read_lexicon('/content/drive/MyDrive/Colab Notebooks/Amplifi Project/lexicons/assertives_hooper1975.txt'),\n","            'entailed_arg': self.read_lexicon('/content/drive/MyDrive/Colab Notebooks/Amplifi Project/lexicons/entailed_arg_berant2012.txt'),\n","            'entailed': self.read_lexicon('/content/drive/MyDrive/Colab Notebooks/Amplifi Project/lexicons/entailed_berant2012.txt'), \n","            'entailing_arg': self.read_lexicon('/content/drive/MyDrive/Colab Notebooks/Amplifi Project/lexicons/entailing_arg_berant2012.txt'), \n","            'entailing': self.read_lexicon('/content/drive/MyDrive/Colab Notebooks/Amplifi Project/lexicons/entailing_berant2012.txt'), \n","            'factives': self.read_lexicon('/content/drive/MyDrive/Colab Notebooks/Amplifi Project/lexicons/factives_hooper1975.txt'),\n","            'hedges': self.read_lexicon('/content/drive/MyDrive/Colab Notebooks/Amplifi Project/lexicons/hedges_hyland2005.txt'),\n","            'implicatives': self.read_lexicon('/content/drive/MyDrive/Colab Notebooks/Amplifi Project/lexicons/implicatives_karttunen1971.txt'),\n","            'negatives': self.read_lexicon('/content/drive/MyDrive/Colab Notebooks/Amplifi Project/lexicons/negative_liu2005.txt'),\n","            'positives': self.read_lexicon('/content/drive/MyDrive/Colab Notebooks/Amplifi Project/lexicons/positive_liu2005.txt'),\n","            'npov': self.read_lexicon('/content/drive/MyDrive/Colab Notebooks/Amplifi Project/lexicons/npov_lexicon.txt'),\n","            'reports': self.read_lexicon('/content/drive/MyDrive/Colab Notebooks/Amplifi Project/lexicons/report_verbs.txt'),\n","            'strong_subjectives': self.read_lexicon('/content/drive/MyDrive/Colab Notebooks/Amplifi Project/lexicons/strong_subjectives_riloff2003.txt'),\n","            'weak_subjectives': self.read_lexicon('/content/drive/MyDrive/Colab Notebooks/Amplifi Project/lexicons/weak_subjectives_riloff2003.txt')\n","        }\n","        self.lexicon_feature_bits = lexicon_feature_bits\n","\n","\n","    def get_feature_names(self):\n","\n","        lexicon_feature_names = list(self.lexicons.keys())\n","        context_feature_names = [x + '_context' for x in lexicon_feature_names]\n","        pos_names = list(list(zip(*sorted(self.pos2id.items(), key=lambda x: x[1])))[0])\n","        rel_names = list(list(zip(*sorted(self.rel2id.items(), key=lambda x: x[1])))[0])\n","\n","        return lexicon_feature_names + context_feature_names + pos_names + rel_names        \n","\n","    def read_lexicon(self, fp):\n","        out = set([\n","            l.strip() for l in open(fp, errors='ignore') \n","            if not l.startswith('#') and not l.startswith(';')\n","            and len(l.strip().split()) == 1\n","        ])\n","        return out\n","\n","\n","    def lexicon_features(self, words, bits=2):\n","        assert bits in [1, 2]\n","        if bits == 1:\n","            true = 1\n","            false = 0\n","        else:\n","            true = [1, 0]\n","            false = [0, 1]\n","    \n","        out = []\n","        for word in words:\n","            out.append([\n","                true if word in lexicon else false \n","                for _, lexicon in self.lexicons.items()\n","            ])\n","        out = np.array(out)\n","\n","        if bits == 2:\n","            out = out.reshape(len(words), -1)\n","\n","        return out\n","\n","\n","    def context_features(self, lex_feats, window_size=2):\n","        out = []\n","        nwords = lex_feats.shape[0]\n","        nfeats = lex_feats.shape[1]\n","        for wi in range(lex_feats.shape[0]):\n","            window_start = max(wi - window_size, 0)\n","            window_end = min(wi + window_size + 1, nwords)\n","\n","            left = lex_feats[window_start: wi, :] if wi > 0 else np.zeros((1, nfeats))\n","            right = lex_feats[wi + 1: window_end, :] if wi < nwords - 1 else np.zeros((1, nfeats))\n","\n","            out.append((np.sum(left + right, axis=0) > 0).astype(int))\n","\n","        return np.array(out)\n","\n","\n","    def features(self, id_seq, rel_ids, pos_ids):\n","        if self.pad_id in id_seq:\n","            pad_idx = id_seq.index(self.pad_id)\n","            pad_len = len(id_seq[pad_idx:])\n","            id_seq = id_seq[:pad_idx]\n","            rel_ids = rel_ids[:pad_idx]\n","            pos_ids = pos_ids[:pad_idx]\n","        else:\n","            pad_len = 0\n","\n","        toks = [self.id2tok[x] for x in id_seq]\n","        # build list of [word, [tok indices the word came from]]\n","        words = []\n","        word_indices = []\n","        for i, tok in enumerate(toks):\n","            if tok.startswith('##'):\n","                words[-1] += tok.replace('##', '')\n","                word_indices[-1].append(i)\n","            else:\n","                words.append(tok)\n","                word_indices.append([i])\n","\n","        # get expert features\n","        lex_feats = self.lexicon_features(words, bits=self.lexicon_feature_bits)\n","        context_feats = self.context_features(lex_feats)\n","        expert_feats = np.concatenate((lex_feats, context_feats), axis=1)\n","        # break word-features into tokens\n","        feats = np.concatenate([\n","            np.repeat(np.expand_dims(word_vec, axis=0), len(indices), axis=0) \n","            for (word_vec, indices) in zip(expert_feats, word_indices)\n","        ], axis=0)\n","\n","        # add in the pos and relational features\n","        pos_feats = np.zeros((len(pos_ids), len(POS2ID)))\n","        pos_feats[range(len(pos_ids)), pos_ids] = 1\n","        rel_feats = np.zeros((len(rel_ids), len(REL2ID)))\n","        rel_feats[range(len(rel_ids)), rel_ids] = 1\n","        \n","        feats = np.concatenate((feats, pos_feats, rel_feats), axis=1)\n","\n","        # add pad back in                \n","        feats = np.concatenate((feats, np.zeros((pad_len, feats.shape[1]))))\n","\n","        return feats\n","\n","\n","    def featurize_batch(self, batch_ids, rel_ids, pos_ids, padded_len=0):\n","        \"\"\" takes [batch, len] returns [batch, len, features] --> i.e. for every sentence in the batch, for every word in len we have the features\"\"\"\n","\n","        batch_feats = [\n","            self.features(list(id_seq), list(rel_ids), list(pos_ids)) \n","            for id_seq, rel_ids, pos_ids in zip(batch_ids, rel_ids, pos_ids)]\n","        batch_feats = np.array(batch_feats)\n","        return batch_feats\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"UMY_xtSNzaK9"},"source":["# Dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rgi1udTsylsL"},"outputs":[],"source":["# import datasets\n","source_folder = \"/content/drive/MyDrive/Colab Notebooks/Amplifi Project/Data/Processed Datasets/\"\n","train_df = pd.read_csv(source_folder + dataset + '_train.csv', delimiter=',')\n","val_df = pd.read_csv(source_folder + dataset + '_valid.csv', delimiter=',')\n","test_df = pd.read_csv(source_folder + dataset + '_test.csv', delimiter=',')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SNYPze_7zbtm"},"outputs":[],"source":["# hyperparameters\n","max_len = 200 # we cap the max length at 200, even though some data samples have larger length\n","train_batch_size = 32\n","val_batch_size = 32\n","test_batch_size = 32\n","\n","target_list = ['label']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6_fg1XkIXFIt"},"outputs":[],"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EdoY9lTmzuVR"},"outputs":[],"source":["class CustomDataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, df, tokenizer, max_len):\n","        self.tokenizer = tokenizer\n","        self.df = df\n","        self.title = df['text']\n","        self.pos = df['pos_tags']\n","        self.rel = df['rel_tags']\n","        self.targets = self.df[target_list].values\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.title)\n","\n","    def __getitem__(self, index):\n","        title = str(self.title[index])\n","        title = \" \".join(title.split())\n","\n","        pos_str = str(self.pos[index])\n","        pos = []\n","        for tag in pos_str.split():\n","          try:\n","            pos.append(POS2ID[tag])\n","          except:\n","            POS2ID['<UNK>']\n","        pos = torch.tensor(pos)\n","        pos_ids = torch.zeros(max_len, dtype=int)\n","        if len(pos) > max_len:\n","          pos_ids[:] = pos[:max_len]\n","        else:\n","          pos_ids[:len(pos)] = pos\n","\n","        rel_str = str(self.rel[index])\n","        rel = []\n","        for tag in rel_str.split():\n","          try:\n","            rel.append(REL2ID[tag])\n","          except:\n","            REL2ID['<UNK>']\n","        rel = torch.tensor(rel)\n","        rel_ids = torch.zeros(max_len, dtype=int)\n","        if len(rel) > max_len:\n","          rel_ids[:] = rel[:max_len]\n","        else:\n","          rel_ids[:len(rel)] = rel\n","\n","        inputs = self.tokenizer.encode_plus(\n","            title,\n","            None,\n","            add_special_tokens=False, # we do not want SOS and EOS tokens\n","            max_length=self.max_len,\n","            padding='max_length',\n","            return_token_type_ids=False, # we cannot have this if we do not have SOS and EOS tokens\n","            truncation=True,\n","            return_attention_mask=True,\n","            return_tensors='pt'\n","        )\n","\n","        return {\n","            'text': title,\n","            'input_ids': inputs['input_ids'].flatten(), # ID of each token in the text\n","            'pos_ids': pos_ids,\n","            'rel_ids': rel_ids,\n","            'attention_mask': inputs['attention_mask'].flatten(),\n","            # 'token_type_ids': inputs[\"token_type_ids\"].flatten(),\n","            'targets': torch.FloatTensor(self.targets[index]) # Bias and Unbias label (0 when False, 1 when True)\n","        }"]},{"cell_type":"markdown","metadata":{"id":"TI8Bp6dkglE7"},"source":["## continue"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cMBczZ-F0G5M"},"outputs":[],"source":["train_dataset = CustomDataset(train_df, tokenizer, max_len)\n","val_dataset = CustomDataset(val_df, tokenizer, max_len)\n","test_dataset = CustomDataset(test_df, tokenizer, max_len)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZRdmTNW30IjD"},"outputs":[],"source":["train_loader = torch.utils.data.DataLoader(train_dataset, \n","    batch_size=train_batch_size,\n","    shuffle=True,\n","    num_workers=0\n",")\n","\n","val_loader = torch.utils.data.DataLoader(val_dataset, \n","    batch_size=val_batch_size,\n","    shuffle=True,\n","    num_workers=0\n",")\n","\n","test_loader = torch.utils.data.DataLoader(test_dataset, \n","    batch_size=test_batch_size,\n","    shuffle=True,\n","    num_workers=0\n",")"]},{"cell_type":"markdown","metadata":{"id":"VLAyQr3jBwMK"},"source":["# Feature Extraction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H65-o5vjDnNW"},"outputs":[],"source":["tok2id = tokenizer.vocab\n","tok2id['<del>'] = len(tok2id)\n","lexicon_feature_bits = 1\n","featurizer = Featurizer(tok2id, lexicon_feature_bits=lexicon_feature_bits)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"apNgGMcHhVma"},"outputs":[],"source":["for data in train_loader:\n","  break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AWeF1wLnZE6B"},"outputs":[],"source":["feats = featurizer.featurize_batch(\n","            data['input_ids'].detach().cpu().numpy(), \n","            data['rel_ids'].detach().cpu().numpy(), \n","            data['pos_ids'].detach().cpu().numpy(), \n","            padded_len=data['input_ids'].shape[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1663329927098,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"},"user_tz":-60},"id":"ussbSf_Bm_9S","outputId":"dfa63a58-941c-4d4e-d19d-6a377bbba77c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(32, 200, 100)"]},"metadata":{},"execution_count":57}],"source":["feats.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uw62fAgTAaYq"},"outputs":[],"source":["feats = feats.reshape(32,-1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1663329927100,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"},"user_tz":-60},"id":"rzwXOHZ936Tm","outputId":"fde0befa-acfc-4158-d0cf-d06058ef97bf"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["106.0"]},"metadata":{},"execution_count":59}],"source":["sum(feats[11])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1663329927100,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"},"user_tz":-60},"id":"YVbMvY8FzUJN","outputId":"801b9912-04a7-4a5f-c917-8b067f050531"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(32, 20000)"]},"metadata":{},"execution_count":60}],"source":["feats.shape"]},{"cell_type":"markdown","metadata":{"id":"DS6kgoITxJWX"},"source":["# GloVe features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YBUjdX7xzQTs"},"outputs":[],"source":["inv_bert_vocab = {v: k for k, v in tokenizer.vocab.items()}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1663329928311,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"},"user_tz":-60},"id":"Dp7Fn-wk1Ljb","outputId":"4bea6c14-7e99-4eba-fbb2-112f72358f9f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([32, 200])"]},"metadata":{},"execution_count":62}],"source":["data['input_ids'].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rPeR8sR006vJ"},"outputs":[],"source":["# account for <unk> words that are not in GloVe and ignore PAD tokens. GloVe embedding of the text is the average of the embeddings of the words.\n","# when calculating the average you count the non-padded words, so you don't divide by the max_length, but by the actual number of tokens in the text."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gLV58NnVxI8n"},"outputs":[],"source":["#Load in pickled embeddings\n","vectors = bcolz.open('/content/drive/MyDrive/Colab Notebooks/Amplifi Project/GloVe/6B.50.dat')[:]\n","words = pickle.load(open('/content/drive/MyDrive/Colab Notebooks/Amplifi Project/GloVe/6B.50_words.pkl', 'rb'))\n","word2idx = pickle.load(open('/content/drive/MyDrive/Colab Notebooks/Amplifi Project/GloVe/6B.50_idx.pkl', 'rb'))\n","glove = {w: vectors[word2idx[w]] for w in words}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SKLEvQs577uP"},"outputs":[],"source":["def glove_featurizer(input_ids):\n","  # Input ids is a vector of input ids (not a batch)\n","\n","  glove_features = torch.zeros(50)\n","  length = 0\n","  for id in input_ids:\n","    if int(id) != 0: # ignore PAD tokens\n","      length += 1\n","      try:\n","        glove_features += glove[inv_bert_vocab[int(id)]]\n","      except:\n","        glove_features += glove['<unk>'] # if the token is not present in GloVe, we assign it as <unk>\n","\n","  glove_features /= length\n","\n","  return glove_features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mm1GE990ClSX"},"outputs":[],"source":["def glove_batch_features(batch):\n","  return torch.stack(list(map(glove_featurizer, batch)))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":462,"status":"ok","timestamp":1663329931382,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"},"user_tz":-60},"id":"cl-8LfnC9zWT","outputId":"c641977f-338c-4c6f-d4de-c0ceb546ff63"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.2615, -0.1262, -0.1709,  ..., -0.3681, -0.2522, -0.2820],\n","        [ 0.0953,  0.0335,  0.1523,  ...,  0.0379, -0.0298,  0.0902],\n","        [ 0.0451,  0.2493, -0.0172,  ..., -0.3245, -0.0361,  0.1465],\n","        ...,\n","        [ 0.3463, -0.1060,  0.0498,  ..., -0.0148, -0.0910, -0.4903],\n","        [ 0.2126,  0.1406, -0.0653,  ..., -0.2112,  0.0603, -0.3135],\n","        [ 0.2258,  0.4177, -0.2521,  ..., -0.2484, -0.1536, -0.2510]],\n","       dtype=torch.float64)"]},"metadata":{},"execution_count":67}],"source":["glove_batch_features(data['input_ids'])"]},{"cell_type":"markdown","metadata":{"id":"W_diGAld7E0G"},"source":["# Simple classifier model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"holh8sjP7Gft"},"outputs":[],"source":["# number of features (len of X cols)\n","input_dim = 20000\n","# number of hidden layers\n","hidden_layer1 = 10000\n","hidden_layer2 = 50\n","hidden_layer3 = 100\n","# number of classes (unique of y)\n","output_dim = 1\n","\n","class Classifier(nn.Module):\n","  def __init__(self):\n","    super(Classifier, self).__init__()\n","    self.linear1 = nn.Linear(input_dim, hidden_layer1)\n","    self.linear2 = nn.Linear(hidden_layer1, hidden_layer2)\n","    self.linear3 = nn.Linear(hidden_layer3, output_dim)\n","    self.dropout = torch.nn.Dropout(0.3)\n","  def forward(self, x1, x2):\n","    # x1 = features from featurizer --> 20,000\n","    # x2 = features from GloVe embeddings --> 50\n","    x1 = self.dropout(torch.sigmoid(self.linear1(x1)))\n","    x1 = self.dropout(torch.sigmoid(self.linear2(x1)))\n","    # print(x1.shape)\n","    # print(x2.shape)\n","    x = torch.cat((x1,x2), axis=1)\n","    # print(x.shape)\n","    x = torch.sigmoid(self.linear3(x))\n","    return x"]},{"cell_type":"markdown","metadata":{"id":"Qpg0Fayj8x33"},"source":["# Prep for training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wC5boBzC9Vtn"},"outputs":[],"source":["# Save and Load Functions\n","\n","def save_checkpoint(save_path, model, optimizer, valid_loss):\n","\n","    if save_path == None:\n","        return\n","    \n","    state_dict = {'model_state_dict': model.state_dict(),\n","                  'optimizer_state_dict': optimizer.state_dict(),\n","                  'valid_loss': valid_loss}\n","    \n","    torch.save(state_dict, save_path)\n","    print(f'Model saved to ==> {save_path}')\n","\n","\n","def load_checkpoint(load_path, model, optimizer):\n","\n","    if load_path==None:\n","        return\n","    \n","    state_dict = torch.load(load_path, map_location=device)\n","    print(f'Model loaded from <== {load_path}')\n","    \n","    model.load_state_dict(state_dict['model_state_dict'])\n","    optimizer.load_state_dict(state_dict['optimizer_state_dict'])\n","    \n","    return state_dict['valid_loss']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u6VzZu9-9CGr"},"outputs":[],"source":["def loss_fn(outputs, targets):\n","    return torch.nn.BCELoss()(outputs, targets)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":23552,"status":"ok","timestamp":1663329963329,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"},"user_tz":-60},"id":"zBUF69l18zcZ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e9004ab8-807f-44fe-e9bb-1253176b71bd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model loaded from <== /content/drive/MyDrive/Colab Notebooks/Amplifi Project/Saved Models and Checkpoints/features_glove_model_Mixed.pt\n","features_glove_model_Mixed.pt --> loaded\n"]}],"source":["model = Classifier()\n","model.to(device)\n","optimizer = torch.optim.Adam(params =  model.parameters(), lr=1e-5)\n","\n","destination_folder = \"/content/drive/MyDrive/Colab Notebooks/Amplifi Project/Saved Models and Checkpoints\"\n","\n","try:\n","  load_checkpoint(destination_folder + '/features_glove_model_' + dataset + '.pt', model, optimizer) # comment this if you wannt to train the model from zero\n","  print('features_glove_model_' + dataset + '.pt --> loaded')\n","except:\n","  print('training features_glove_model_' + dataset + ' from scratch')"]},{"cell_type":"markdown","metadata":{"id":"yZlEe6OmL4mR"},"source":["# Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k0K21YVnL5z1"},"outputs":[],"source":["val_targets=[]\n","val_outputs=[]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uFGdne4IL8jj"},"outputs":[],"source":["def train_model(n_epochs, featurizer, training_loader, validation_loader, model, \n","                optimizer, destination_folder, best_valid_loss=np.Inf):\n","   \n","  for epoch in range(1, n_epochs+1):\n","    train_loss = 0\n","    valid_loss = 0\n","\n","    model.train()\n","    print('############# Epoch {}: Training Start   #############'.format(epoch))\n","    for batch_idx, data in enumerate(training_loader):\n","\n","        if batch_idx % round(len(training_loader)/6) == 0:\n","          print(f'--> epoch: {epoch}/{n_epochs} --- step {batch_idx}/{len(training_loader)}')\n","\n","        #print('yyy epoch', batch_idx)\n","        # ids = data['input_ids'].to(device, dtype = torch.long)\n","        # mask = data['attention_mask'].to(device, dtype = torch.long)\n","        # token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n","        targets = data['targets'].to(device, dtype = torch.float)\n","\n","        feats = featurizer.featurize_batch(\n","                data['input_ids'].detach().cpu().numpy(), \n","                data['rel_ids'].detach().cpu().numpy(), \n","                data['pos_ids'].detach().cpu().numpy(), \n","                padded_len=data['input_ids'].shape[1])\n","        \n","        feats = torch.tensor(feats.reshape(feats.shape[0],-1)).to(device, dtype = torch.float)\n","\n","        glove_feats = glove_batch_features(data['input_ids']).to(device, dtype = torch.float)\n","\n","        outputs = model(feats, glove_feats)\n","\n","        optimizer.zero_grad()\n","        loss = loss_fn(outputs, targets)\n","        \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        # train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.item() - train_loss))\n","        train_loss += loss.item()\n","    \n","    print('############# Epoch {}: Training End     #############'.format(epoch))\n","\n","    print('############# Epoch {}: Validation Start   #############'.format(epoch))\n","    ######################    \n","    # validate the model #\n","    ######################\n"," \n","    model.eval()\n","   \n","    with torch.no_grad():\n","      for batch_idx, data in enumerate(validation_loader, 0):\n","\n","            if batch_idx % round(len(validation_loader)/6) == 0:\n","              print(f'--> epoch: {epoch}/{n_epochs} --- step {batch_idx}/{len(validation_loader)}')\n","            \n","            # ids = data['input_ids'].to(device, dtype = torch.long)\n","            # mask = data['attention_mask'].to(device, dtype = torch.long)\n","            # token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n","            targets = data['targets'].to(device, dtype = torch.float)\n","\n","            feats = featurizer.featurize_batch(\n","                    data['input_ids'].detach().cpu().numpy(), \n","                    data['rel_ids'].detach().cpu().numpy(), \n","                    data['pos_ids'].detach().cpu().numpy(), \n","                    padded_len=data['input_ids'].shape[1])\n","                \n","            feats = torch.tensor(feats.reshape(feats.shape[0],-1)).to(device, dtype = torch.float)\n","\n","            glove_feats = glove_batch_features(data['input_ids']).to(device, dtype = torch.float)\n","\n","            outputs = model(feats, glove_feats)\n","\n","            loss = loss_fn(outputs, targets)\n","            # valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.item() - valid_loss))\n","            valid_loss += loss.item()\n","            val_targets.extend(targets.cpu().detach().numpy().tolist())\n","            val_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n","\n","      print('############# Epoch {}: Validation End     #############'.format(epoch))\n","      # calculate average losses\n","      #print('before cal avg train loss', train_loss)\n","      train_loss = train_loss/len(training_loader)\n","      valid_loss = valid_loss/len(validation_loader)\n","      # print training/validation statistics \n","      print('Epoch: {} \\tAvgerage Training Loss: {:.6f} \\tAverage Validation Loss: {:.6f}'.format(\n","            epoch, \n","            train_loss,\n","            valid_loss\n","            ))\n","        \n","      ## TODO: save the model if validation loss has decreased\n","      if valid_loss <= best_valid_loss:\n","        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(best_valid_loss,valid_loss))\n","        # save checkpoint as best model\n","        save_checkpoint(destination_folder + '/features_glove_model_' + dataset + '.pt', model, optimizer, best_valid_loss)\n","        best_valid_loss = valid_loss\n","\n","    print('############# Epoch {}  Done   #############\\n'.format(epoch))\n","\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OpO3RgaWMPQd"},"outputs":[],"source":["tok2id = tokenizer.vocab\n","tok2id['<del>'] = len(tok2id)\n","lexicon_feature_bits = 1\n","featurizer = Featurizer(tok2id, lexicon_feature_bits=lexicon_feature_bits)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YPO4YkkCMP1z","executionInfo":{"status":"ok","timestamp":1663329672928,"user_tz":-60,"elapsed":53745,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"}},"outputId":"f115cb80-9bec-4cf7-82e4-60c784e179e1"},"outputs":[{"output_type":"stream","name":"stdout","text":["############# Epoch 1: Training Start   #############\n","--> epoch: 1/3 --- step 0/56\n","--> epoch: 1/3 --- step 9/56\n","--> epoch: 1/3 --- step 18/56\n","--> epoch: 1/3 --- step 27/56\n","--> epoch: 1/3 --- step 36/56\n","--> epoch: 1/3 --- step 45/56\n","--> epoch: 1/3 --- step 54/56\n","############# Epoch 1: Training End     #############\n","############# Epoch 1: Validation Start   #############\n","--> epoch: 1/3 --- step 0/7\n","--> epoch: 1/3 --- step 1/7\n","--> epoch: 1/3 --- step 2/7\n","--> epoch: 1/3 --- step 3/7\n","--> epoch: 1/3 --- step 4/7\n","--> epoch: 1/3 --- step 5/7\n","--> epoch: 1/3 --- step 6/7\n","############# Epoch 1: Validation End     #############\n","Epoch: 1 \tAvgerage Training Loss: 0.690107 \tAverage Validation Loss: 0.697363\n","Validation loss decreased (0.697882 --> 0.697363).  Saving model ...\n","Model saved to ==> /content/drive/MyDrive/Colab Notebooks/Amplifi Project/Saved Models and Checkpoints/features_glove_model_Stereo.pt\n","############# Epoch 1  Done   #############\n","\n","############# Epoch 2: Training Start   #############\n","--> epoch: 2/3 --- step 0/56\n","--> epoch: 2/3 --- step 9/56\n","--> epoch: 2/3 --- step 18/56\n","--> epoch: 2/3 --- step 27/56\n","--> epoch: 2/3 --- step 36/56\n","--> epoch: 2/3 --- step 45/56\n","--> epoch: 2/3 --- step 54/56\n","############# Epoch 2: Training End     #############\n","############# Epoch 2: Validation Start   #############\n","--> epoch: 2/3 --- step 0/7\n","--> epoch: 2/3 --- step 1/7\n","--> epoch: 2/3 --- step 2/7\n","--> epoch: 2/3 --- step 3/7\n","--> epoch: 2/3 --- step 4/7\n","--> epoch: 2/3 --- step 5/7\n","--> epoch: 2/3 --- step 6/7\n","############# Epoch 2: Validation End     #############\n","Epoch: 2 \tAvgerage Training Loss: 0.689330 \tAverage Validation Loss: 0.697522\n","############# Epoch 2  Done   #############\n","\n","############# Epoch 3: Training Start   #############\n","--> epoch: 3/3 --- step 0/56\n","--> epoch: 3/3 --- step 9/56\n","--> epoch: 3/3 --- step 18/56\n","--> epoch: 3/3 --- step 27/56\n","--> epoch: 3/3 --- step 36/56\n","--> epoch: 3/3 --- step 45/56\n","--> epoch: 3/3 --- step 54/56\n","############# Epoch 3: Training End     #############\n","############# Epoch 3: Validation Start   #############\n","--> epoch: 3/3 --- step 0/7\n","--> epoch: 3/3 --- step 1/7\n","--> epoch: 3/3 --- step 2/7\n","--> epoch: 3/3 --- step 3/7\n","--> epoch: 3/3 --- step 4/7\n","--> epoch: 3/3 --- step 5/7\n","--> epoch: 3/3 --- step 6/7\n","############# Epoch 3: Validation End     #############\n","Epoch: 3 \tAvgerage Training Loss: 0.690693 \tAverage Validation Loss: 0.698142\n","############# Epoch 3  Done   #############\n","\n"]}],"source":["epochs = 3\n","trained_model = train_model(epochs, featurizer, train_loader, val_loader, model, optimizer, destination_folder)"]},{"cell_type":"markdown","metadata":{"id":"LiiTCglsNohu"},"source":["# Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6TFanQFENpd5","executionInfo":{"status":"ok","timestamp":1663330028865,"user_tz":-60,"elapsed":28327,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"}},"outputId":"efbecc23-0e15-4fd5-e38f-db9790cd7224"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model loaded from <== /content/drive/MyDrive/Colab Notebooks/Amplifi Project/Saved Models and Checkpoints/features_glove_model_Mixed.pt\n","accuracy = 56.599999999999994 %\n"]}],"source":["# testing\n","corrects = 0\n","totals = 0\n","\n","test_model = Classifier()\n","test_model.to(device)\n","optimizer = torch.optim.Adam(params =  test_model.parameters(), lr=1e-5)\n","destination_folder = \"/content/drive/MyDrive/Colab Notebooks/Amplifi Project/Saved Models and Checkpoints\"\n","load_checkpoint(destination_folder + '/features_glove_model_' + dataset + '.pt', test_model, optimizer)\n","\n","with torch.no_grad():\n","  test_model.eval() \n","  for batch_idx, data in enumerate(test_loader, 0): \n","    feats = featurizer.featurize_batch(\n","                data['input_ids'].detach().cpu().numpy(), \n","                data['rel_ids'].detach().cpu().numpy(), \n","                data['pos_ids'].detach().cpu().numpy(), \n","                padded_len=data['input_ids'].shape[1])\n","        \n","    feats = torch.tensor(feats.reshape(feats.shape[0],-1)).to(device, dtype = torch.float)\n","\n","    glove_feats = glove_batch_features(data['input_ids']).to(device, dtype = torch.float)\n","\n","    outputs = test_model(feats, glove_feats)\n","\n","    final_output = outputs.cpu().detach().numpy().tolist()\n","    pred_class = np.round(final_output)\n","    corrects += np.count_nonzero((data['targets'] - pred_class) == 0.)\n","    totals += len(pred_class)\n","  \n","  # Calculate accuracy of test set\n","  acc = corrects / totals\n","\n","  print(f'accuracy = {acc * 100} %')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":509},"id":"scGInPYaeXPn","executionInfo":{"status":"ok","timestamp":1663331708959,"user_tz":-60,"elapsed":14273,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"}},"outputId":"268e7b4c-4dae-488a-d532-16cb4ef12e5f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model loaded from <== /content/drive/MyDrive/Colab Notebooks/Amplifi Project/Saved Models and Checkpoints/features_glove_model_Mixed.pt\n","Classification Report:\n","remember: 1 = BIASED, 0 = UNBIASED\n","              precision    recall  f1-score   support\n","\n","           1     0.6331    0.4305    0.5125       525\n","           0     0.5350    0.7242    0.6154       475\n","\n","    accuracy                         0.5700      1000\n","   macro avg     0.5840    0.5773    0.5639      1000\n","weighted avg     0.5865    0.5700    0.5614      1000\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 2 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAW4AAAEWCAYAAABG030jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3debxVdb3/8df7HBAxEBBQUVHAnCdEUtPrnElmV7NuSuVQGtnVrqZW1/SnSfPgUBe1cMopzTnnJLOUUhGVmJxANBEUxUARUIbP74/1Pbg5nLPPPoe9zj4L3s8e69Fa3zV8v5uz/Zzv+a7voIjAzMyKo67WBTAzs9Zx4DYzKxgHbjOzgnHgNjMrGAduM7OCceA2MysYB25bbZK6Srpb0nxJt6zGc74k6cFqlq0WJN0v6bhal8PWXA7caxFJX5Q0XtICSbNTgPmPKjz688BGQO+I+K+2PiQiboiIT1ahPCuRtL+kkHRHo/RdUvpfK3zO9yVd39J1EfGpiLimjcU1a5ED91pC0unAxcCPyYLs5sClwOFVePwWwAsRsbQKz8rLm8DHJfUuSTsOeKFaGSjj/6Ysd/6SrQUk9QBGAidHxO0R8V5ELImIuyPi2+maLpIuljQrbRdL6pLO7S9ppqQzJM1JtfWvpHPnA+cCR6Wa/AmNa6aSBqSabad0fLyklyS9K2mGpC+VpI8tuW8vSU+mJpgnJe1Vcu6vkn4g6e/pOQ9K6lPmn+ED4E7g6HR/PXAUcEOjf6tfSXpV0juSnpK0T0ofBnyv5HP+s6QcP5L0d2AhMCilnZjOXybptpLn/0zSQ5JU8Q/QrBEH7rXDx4F1gTvKXHM2sCcwGNgF2B04p+T8xkAPYFPgBOASSb0i4jyyWvwfIqJbRFxZriCSPgL8GvhURHQH9gImNHHdBsC96drewIXAvY1qzF8EvgJsCKwDnFkub+Ba4Ni0fwgwGZjV6Jonyf4NNgB+D9wiad2IeKDR59yl5J5jgBFAd+CVRs87A9gp/VLah+zf7rjwXBO2Ghy41w69gbdaaMr4EjAyIuZExJvA+WQBqcGSdH5JRNwHLAC2aWN5lgM7SuoaEbMjYkoT13waeDEirouIpRFxI/Ac8JmSa66OiBciYhFwM1nAbVZE/APYQNI2ZAH82iauuT4i5qY8LwC60PLn/F1ETEn3LGn0vIVk/44XAtcD34yImS08z6wsB+61w1ygT0NTRTM2YeXa4ispbcUzGgX+hUC31hYkIt4ja6I4CZgt6V5J21ZQnoYybVpy/HobynMdcApwAE38BSLpTEnPpuaZeWR/ZZRrggF4tdzJiHgCeAkQ2S8Ys9XiwL12eAx4HziizDWzyF4yNticVZsRKvUesF7J8calJyPiTxFxMNCPrBZ9eQXlaSjTa20sU4PrgP8G7ku14RVSU8Z3gC8AvSKiJzCfLOACNNe8UbbZQ9LJZDX3Wen5ZqvFgXstEBHzyV4gXiLpCEnrSeos6VOSfp4uuxE4R1Lf9JLvXLI/7dtiArCvpM3Ti9GzGk5I2kjS4amt+32yJpflTTzjPmDr1IWxk6SjgO2Be9pYJgAiYgawH1mbfmPdgaVkPVA6SToXWL/k/BvAgNb0HJG0NfBD4MtkTSbfkVS2ScesJQ7ca4nUXns62QvHN8n+vD+FrKcFZMFlPDARmAQ8ndLaktcY4A/pWU+xcrCtS+WYBbxNFkS/0cQz5gKHkb3cm0tWUz0sIt5qS5kaPXtsRDT118SfgAfIugi+Aixm5WaQhsFFcyU93VI+qWnqeuBnEfHPiHiRrGfKdQ09dszaQn65bWZWLK5xm5kVjAO3mVnBOHCbmRWMA7eZWcGUG5BRUyPHTPNbU1vFb26bWOsiWAc06zdHrvbcL113PaXimLPomVE1nWvGNW4zs4LpsDVuM7N2VaAZeR24zcwA6uprXYKKOXCbmQEUaIp0B24zM3BTiZlZ4bjGbWZWMK5xm5kVjGvcZmYF414lZmYF46YSM7OCcVOJmVnBuMZtZlYwDtxmZgVT75eTZmbF4jZuM7OCKVBTSXFKamaWJ6nyrexjtK6kcZL+KWmKpPNT+g2Snpc0WdJVkjqn9P0lzZc0IW3ntlRU17jNzKCaNe73gQMjYkEKzmMl3Q/cAHw5XfN74ETgsnT8aEQcVmkGDtxmZlC1Nu6ICGBBOuyctoiI+z7MSuOAzdqah5tKzMwgG/Je4SZphKTxJduI0kdJqpc0AZgDjImIJ0rOdQaOAR4oueXjqWnlfkk7tFRU17jNzKBVTSURMRoYXeb8MmCwpJ7AHZJ2jIjJ6fSlwCMR8Wg6fhrYIjWtHArcCWxVLn/XuM3MoGovJ0tFxDzgYWBYloXOA/oCp5dc805ELEj79wGdJfUp91wHbjMzyGrclW7lHiP1TTVtJHUFDgaek3QicAgwPCKWl1y/sZT9NpC0O1lcnlsuDzeVmJlBNXuV9AOukVRPFoRvjoh7JC0FXgEeS3H69ogYCXwe+EY6vwg4Or3gbJYDt5kZVG0+7oiYCOzaRHqT8TYiRgGjWpOHA7eZGXjIu5lZ4RRoyLsDt5kZuMZtZlY0cuA2MysWB24zs4JRnQO3mVmhuMZtZlYwDtxmZgXjwG1mVjTFidsO3GZm4Bq3mVnh1NV55KSZWaG4xp2kOWkbVnJ4ISLm55mfmVmbFSdu5xO4JXUBfgscAcwg+yfZQtIdwEkR8UEe+ZqZtVWRatx5NeqcTbaycf+I2DUiBgObk/2i+H855Wlm1maSKt5qLa/AfSTwtYh4tyEh7f838Nmc8jQzazPVqeKt7HOkdSWNS6u2T5F0fkofKOkJSdMk/UHSOim9Szqels4PaKmseQXu5RGxsHFiWhCz7JI8Zma1UMUa9/vAgRGxCzAYGCZpT+BnwEUR8VHg38AJ6foTgH+n9IvSdWXlFbhDUi9JGzTegOUt3m1m1s6qFbgjsyAddk5bAAcCt6b0a8jeAQIcno5J5w9SC5nk1aukB/AUTb+ndY3bzDqc1rRdSxoBjChJGh0Ro0vO15PFwI8ClwDTgXkRsTRdMhPYNO1vCrwKEBFLJc0HegNvNZd/LoE7Igbk8Vwzs7y0JnCnID26zPllwODUJfoOYNvVLmCJXJpKJH25ZH/vRudOySNPM7PVolZsFYqIecDDwMeBnpIaKsubAa+l/deA/gDpfA9gbrnn5tXGfXrJ/v81OvfVnPI0M2uzurq6irdyJPVNNW0kdQUOBp4lC+CfT5cdB/wx7d+Vjknn/xIRZZuU82rjVjP7TR2bmdVcFftn9wOuSe3cdcDNEXGPpKnATZJ+CDwDXJmuvxK4TtI04G3g6JYyyCtwRzP7TR2bmdVeleJ2REwEdm0i/SVg9ybSFwP/1Zo88grc20qaSPZPsWXaJx0PyinPQnrv32/y2LUXsOjdeQjx0b2Hse0Bh/P0HVfy2uRx1NV3oluffnz8y6exznrdAPj3azMYd+MolixeCBKf+s7F1Hdep8afxKppk15d+dXxQ+m7fhci4PqxM7jyL9PZftMe/PRLg/lIl07MnLuQk696kgWLl9K5Xvz8S0PYeYueLI/g3Jsn8tgLzXZKsCZ0hBGRlcorcG+X03PXOHV19Qw58kQ26P9RlixeyP0/O5V+2+5Kv213ZfB/Hk9dfT3P3HkVUx68mV2P+CrLly3jH9f8kr2OPYNemw3i/QXvoPr6Wn8Mq7Kly4KRt05i0qvz+EiXTjzwvQN45Nk5/PKYIYy8bRKPv/gWR++1Bd84eGt+cfdUvvQfAwE46AcP0bt7F244ZS8+9dOHKd9SaqWKFLhzeTkZEa+UbsACYAjQJx1b0rXHBmzQ/6MAdF53PXps3J+F8+bSb7sh1KWA3Gfgtiycl71knv3c0/TcdAC9Nsv+cOnSbX3q6hy41zRz3lnMpFfnAfDe+0uZ9vq79OvZlUEbdePxF7Oa9CPPzuHTQzYBYOt+3Rn7/BwA5r77PvMXLWGXLXrVpvAFtdbPVSLpHkk7pv1+wGSy3iTXSTotjzzXBAvmvsHbM1+iz4BtVkqf/tgYNtl+NwDenfMaIP4y6v9x30//hyljbm3iSbYm2az3euzYvydPz3ibF2a9w7Bd+gFw2JBN2aRXVwCmzJzPJ3fuR32d6N97PXbevOeKc1aZas1V0h7y6g44MCImp/2vAGMi4jPAHpTpDihphKTxksaPv/emnIrWMS15fxGPXvEjdvvc1+jcdb0V6ZMfuAnV1TPgYwcAsHzZMt58aSp7HX8mnzz958z852O8/vyEWhXbcrZel3quGLEH5948kQWLl3L6tU9x3H6DeOCsA+i2bic+WJrNIHHTP15h9rxFPHDWAYz8ws6Mf+ltli93O0lrFKnGnVcb95KS/YOAyyGbIVBSs3OVlI5GGjlm2lrzrVu+bCmPXv5jBgw9gM0HfzheafrjY3ht8pMc9D8/WvFlWa9nHzbcckfW7dYDgE12GMrbr05n420G16Tslp9OdeKKEXty+7hXuX/CLACmvbGA4b/+OwCDNuzGQTttDMCy5cH3b5m04t67vr0f0+csWPWh1qyOEJArlVeN+1VJ35T0WbK27QdgRWf0zjnlWUgRweM3/Ir1N+7Pdgd9OOPtrKnjmfrn29jv6+fSaZ11V6T3234I82a9zNIPFrN82TLmTJtEj43716LolrMLjh3Ci6+/y+iHpq1I6929CwASnHroNlz3yAwAunaup+s62buOfbfbkKXLgxdnv7vqQ61ZUuVbreVV4z4BGAl8AjgqDfsE2BO4Oqc8C+nNl6YyY9xf6LnJAO77STYbwC7/eRzjb/kty5cu4S+jzgag94Bt2WP4KXRZrzvbHXgED/z8WyCxyQ5D2XTHVbqGWsHtvmVv/mvPLZg6cz5jzj4QgJ/8cQoDN+zG8ftlL6bvf2YWN/0je9ffe/0u3PjNvVkewevzFvPNq5+sWdmLqkg1brUwsrK6mUnrAp+JiFtaunZtaiqxyv3mtoktX2RrnVm/OXK1o+423/1TxTHn+Z8dUtMon/t69JLqJR0q6TrgFeCovPM0M2stN5UAkvYDvggcCowD9ibrbbLKyjhmZrVW1wG6+VUqr1XeZwL/Ai4Dzky9SWY4aJtZR9URatKVyqup5FZgE7Jmkc9I+gieXMrMOrAi9ePOa8j7acBA4AJgf+B5oK+kL0jqlkeeZmarw23cZAtmkk0c/rCkzsAwsnlmLwX65JWvmVlbtLRAQkeSW+AuFRFLgLuBu9MgHDOzDqUj1KQrldfLyUmUb9PeOY98zczaqiO0XVcqrxr3YTk918wsF9WK25L6A9cCG5FVYEdHxK8k/QFomPqzJzAvIgZLGkC2JuXz6dzjEXFSuTxyCdxNzbktqQ8wt6VFMM3MaqGKNe6lwBkR8bSk7sBTksZExIrBh5IuAOaX3DM9IiqeKS6v+bj3lPRXSbdL2lXSZLI5ud+QNCyPPM3MVke1epVExOyIeDrtv0tWm970w3wk4AvAjW0ta16vUUcBPyYr2F+AEyNiY2Bf4Cc55Wlm1mZ1dap4K107IG0jmnpmagbZFXiiJHkf4I2IeLEkbaCkZyT9TdI+LZU1rzbuThHxIICkkRHxOEBEPFekFwBmtvZoTWwqXTugzPO6AbcBp0XEOyWnhrNybXs2sHlEzJW0G3CnpB0a3bOSvAJ36WIJixqdcxu3mXU41axTprErtwE3RMTtJemdgCOB3RrSIuJ94P20/5Sk6cDWwPjmnp9X4N5F0juAgK5pn3S8bvO3mZnVRrVaA1Ib9pXAsxFxYaPTnwCei4iZJdf3Bd6OiGWSBgFbAS+VyyOvXiVedtzMCqWKNe69gWOASZIaFoT9XkTcRzZ6vPFLyX2BkZKWkLVWnBQRb5fLoF1GTpqZdXTVmtY1IsaStS40de74JtJuI2tWqZgDt5kZHjlpZlY4DtxmZgVToLjtwG1mBq5xm5kVToHitgO3mRkUa7HgFucqkXSqpPWVuVLS05I+2R6FMzNrL3VSxVutVTLJ1FfTmPlPAr3IOpb/NNdSmZm1szVtzcmGYh4KXBcRU1SkVnwzswoUKaxVErifkvQg2artZ6WJwZe3cI+ZWaEUqIm7osB9AjAYeCkiFkrqDXwl32KZmbWvIr2cbDZwSxrSKGlQkf6UMDNrDTU9vUiHVK7GfUGZcwEcWOWymJnVTIEq3M0H7og4oD0LYmZWS0VqUaikH/d6ks6RNDodbyXpsPyLZmbWforUHbCSftxXAx8Ae6Xj14Af5lYiM7MaWNMG4GwZET8HlgBExEKamSTczKyoWrPKezmS+kt6WNJUSVMknZrSvy/pNUkT0nZoyT1nSZom6XlJh7RU1kq6A34gqStpkV9JW5IWtjQzW1NUsSK9FDgjIp5O416ekjQmnbsoIn65cr7anmxJsx2ATYA/S9o6IpY1l0Elgfs84AGgv6QbyNZTO77VH8XMrAOrVhNIRMwGZqf9dyU9C2xa5pbDgZvSau8zJE0Ddgcea7asFRRiDNly8seTLXI5NCL+WuFnMDMrBLVmk0ZIGl+yjWjymdIAYFfgiZR0iqSJkq6S1CulbQq8WnLbTMoH+orauAH2Aw4CDgD2qfAeM7PCkFTxFhGjI2JoyTa6ied1I1sE+LQ0Ud9lwJZkI9FnU36sTFktNpVIuhT4KB8uKf91SZ+IiJPbmqmZWUdTzQE4kjqTBe0bIuJ2gIh4o+T85cA96fA1oH/J7ZultGZV0sZ9ILBdRDS8nLwGmFLpBzAzK4JqzVWSZk+9Eng2Ii4sSe+X2r8BPgtMTvt3Ab+XdCHZy8mtgHHl8qgkcE8DNgdeScf9U5qZ2RqjiiMn9yZbt2CSpAkp7XvAcEmDyXrovQx8HSBNlX0zMJWsR8rJ5XqUQPlJpu5OGXQHnpU0Lh3vQQu/DczMiqZaTSURMZamx7rcV+aeHwE/qjSPcjXuX5Y5Z2a2RinSXCXlJpn6W3sWxMyslooTtiubZGpPSU9KWiDpA0nLJL3THoUzM2sv9XWqeKu1Sl5OjiIbjnkLMBQ4Ftg6z0KZmbW3IjWVVDQAJyKmAfURsSwirgaG5VssM7P2VaRpXSupcS+UtA4wQdLPyUb8VDri0sysEDrCdK2VqiQAH5OuOwV4j6wf95F5FsrMrL0VqcatNCCydTdJf4iIo3IozwqLl9L6gtkar9fHTql1EawDWvTMqNUOpyff8WzFMeeSz25X0/BdSVNJUz5e1VKYmdVYfUeoSleorYHbzGyN0gF6+VWs3JD3Ic2dAjrnUxwzs9pYIwI35eeKfa7aBTEzq6Ui9eMuN+T9gPYsiJlZLa0pNW4zs7VGgSrcDtxmZgCdChS5HbjNzChWjbuS2QEl6cuSzk3Hm0vaPf+imZm1nzqp4q3WKhnyfinZgJvh6fhd4JLcSmRmVgPVGvIuqb+khyVNlTRF0qkp/ReSnpM0UdIdknqm9AGSFkmakLbftFTWSppK9oiIIZKeAYiIf6dJp8zM1hhV7FWyFDgjIp6W1B14StIYYAxwVkQslfQz4Czgu+me6RExuNIMKgncSyTVk603iaS+wPLWfAozs46uWgskpJXcZ6f9dyU9C2waEQ+WXPY48Pm25lFJU8mvgTuADSX9CBgL/LitGZqZdUR1qnyTNELS+JJtRFPPlDQA2BV4otGprwL3lxwPlPSMpL9J2qelsrZY446IGyQ9BRxENtz9iIh4tqX7zMyKRK1YdTIiRgOjyz5P6gbcBpwWEe+UpJ9N1pxyQ0qaDWweEXMl7QbcKWmH0nsaazFwS9ocWAjcXZoWEf9q6V4zs6Ko5shJSZ3JgvYNEXF7SfrxwGHAQZHm1I6I94H30/5TkqaTLQ85vrnnV9LGfS9Z+7aAdYGBwPPADm34PGZmHVK1AreySU+uBJ6NiAtL0ocB3wH2i4iFJel9gbcjYpmkQcBWwEvl8qikqWSnRoUaAvx3az6ImVlHV8VJpvYmWzlskqQJKe17ZO8LuwBjUl6PR8RJwL7ASElLyDp+nBQRb5fLoNUjJ1MXlz1ae5+ZWUdWX6WVdCNiLDTZYH5fM9ffRtasUrFK2rhPLzmsA4YAs1qTiZlZR9cRRkRWqpIad/eS/aVkbd6t+u1gZtbRrTHTuqaBN90j4sx2Ko+ZWU0UqMJddumyTmlo5t7tWSAzs1qoa0U/7lorV+MeR9aePUHSXcAtwHsNJ0v7JpqZFd0aUeMusS4wFziQD/tzB+DAbWZrjE4FauQuF7g3TD1KJvNhwG4QuZbKzKydrSk17nqgG033R3TgNrM1yprSHXB2RIxst5KYmdVQgeJ22cBdoI9hZrZ6qjRwsl2UC9wHtVspzMxqbI1oKmlpkhMzszXJGhG4qyVNWUhEvJl3XmZmbVWcsJ1Ts44y35f0Ftnc3S9IelPSuXnkZ2a2uqq1ynt7yKs9/ltkc9J+LCI2iIhewB7A3pK+lVOeZmZtJqnirdbyCtzHAMMjYkZDQkS8BHwZODanPM3M2qyuFVut5VWGzhHxVuPE1M7dOac8zczarE6qeCtHUn9JD0uaKmmKpFNT+gaSxkh6Mf1/r5QuSb+WNE3SxLTKWPmyVuUTr+qDNp4zM6uJKjaVLAXOiIjtgT2BkyVtD/wv8FBEbAU8lI4BPkW2zuRWwAjgspYyyKtXyS6SmlpavmHBYTOzDqVatdiImA3MTvvvSnoW2BQ4HNg/XXYN8Ffguyn92rTq++OSekrql57TpFwCd0TU5/FcM7O8tOalo6QRZLXjBqMjYnQT1w0AdgWeADYqCcavAxul/U2BV0tum5nSmg3ceXUHPLBkf2Cjc0fmkaeZ2epQK7aIGB0RQ0u2poJ2N7JlHk+LiJVaIFLtus2T9eXVxv3Lkv3G61Oek1OeZmZtVi9VvLVEUmey2HdDyaIzb0jql873A+ak9NeA/iW3b5bSmpVX4FYz+00dm5nVXLUG4Chrc7kSeDYiLiw5dRdwXNo/DvhjSfqxqXfJnsD8cu3bkN/LyWhmv6ljM7OaU/XqlHuTjWWZJGlCSvse8FPgZkknAK8AX0jn7gMOBaYBC4GvtJRBXoF7UFqnUiX7pOOBzd9mZlYb1RoQGRFjab5lYZVZV1N798mtySOvwH14yf4vG51rfGxmVnNryirvbRYRfys9Tg31OwKvRcScpu8yM6udDjAFScXy6g74G0k7pP0ewD+Ba4FnJA3PI08zs9VRrSHv7VLWnJ67T0RMSftfAV6IiJ2A3YDv5JSnmVmb1anyrdbyauMunY/kYOAWgIh4vSNMiWhm1lgVe5XkLq/APU/SYWSdyPcGTgCQ1AnomlOeZmZtVqQ6ZV5NJV8HTgGuJhvu+XpKPwi4N6c8C+vcc85i/30+zpGHH7YibdSvL+bzn/0MXzjycL7+ta8yZ84bAMx4aTrHfPEohg7ekWuuvrJWRbacdVmnE49edyZP/OF/eerWsznnpENXOn/Bdz7Pm3+/YJX7jjhoMIueGcWQ7Tdvr6KuMdSK/9VaLoE7Il6IiGERMTgifleS/ifgpjzyLLLDjziSy357xUppx3/1RG69425uvv2P7Lvf/vz2sksAWL9HT7571tkc95UTalFUayfvf7CUYSN+zR5H/ZQ9jv4Jn9xre3bfaQAAQ7bfnJ7d11vlnm7rdeHkL+7PuIkzVjlnLStSG3e7LOYgaXtJP5A0jQrmml3b7Db0Y6zfo8dKad26dVuxv3jRohUzl/Xu3Zsdd9qZTp1yX+fZauy9Rdmros6d6unUqZ6IoK5O/Pi0Izj7V3eucv15/30YF1w9hsUfLG3voq4RitSrJLf/+tN0hsPTtgTYAhgaES/nleea5v9+dRF333Un3bp154qrr611cayd1dWJf/z+u2zZvy+//cMjPDn5FU4evj/3/m0Sr7+18nT3g7fdjM027sUDY6fwreM+UaMSF1vtw3Hl8urH/RhZW3Yn4HMRsRvwbktBW9IISeMljb/y8lVmSVzrfPPUb/HgQ3/j04d9hpt+f32ti2PtbPnyYM+jf8pHDzmHoTtuwd5DtuTIg3fl0ptWGt+GJH52xuf47gW3N/Mkq0SRatx5NZW8AXQnmyi8b0prcXKp0jluT/jaiJYuX2sc+unP8OcxD9a6GFYj8xcs4m/jX2C/oVszqH9fptx1Hs/dez7rrduZyX88j+4f6cL2W/bjwStO5bl7z2f3nQZw68Vf9wvKVmrNfNy1lteQ9yPSiMkjge9L2groKWn3iBiXR55rmldeeZktthgAwMMPP8TAgYNqWyBrV316dWPJkmXMX7CIdbt05qA9tuWC3/2ZgQd/b8U1b/79AnY8/HwA+h/4vyvS/3T5qZx10R08PfVf7V7uQusIEblCubVxR8R8su6AV0vaiGwKw4skbR4R/cvfvXb57pmnM/7Jccyb928OPnBfvnHyNxn7yCO8/PIM6upEv36bcs552X+gb735JsOP+hzvLVhAXV0d1193DXfcdd9KLzOt+Dbusz6XjzyG+ro66urEbWOe5v5HJ9e6WGu0jtAEUillMwq2Y4bSFhHxSkvXLV7qebttVb0+dkqti2Ad0KJnRq121H3ypfkVx5yPDepR0yifS41b0t2Ub9P+zzzyNTNrs+JUuHNrKvGc22ZWKB1hRGSl2mU+bjOzjq6aTdySrgIOA+ZExI4p7Q/ANumSnsC8iBicxrw8Czyfzj0eESeVe35eTSVbka2x9m/gQuByYB9gOnBCRIzPI18zs7aqcn37d8AosnUIAIiIo1bkJV0AzC+5fnpEDK704Xn1474aeAyYBTwBXAX0Ac4ELskpTzOzNpNU8daSiHgEeLuZfETWy+7GtpY1r8DdLQ2m+SWwKCJuiYjFETEG6JJTnmZmbSa1ZvtwlHfaWjNicB/gjYh4sSRtoKRnJP1N0j4tPSCvl5PLS/bfKXPOzKxDaE1TSUSMBto6L8dwVq5tzwY2j4i5knYD7pS0Q0Q0jp0r5BW4t5U0kezfYsu0Tzr2EEAz63jaoVNJWkzmSLJlHAGIiPeB99P+U5KmA1sDzb4LzCtwb5fTc83MctFO3QE/ATwXETNX5Cv1Bd6OiGWSBgFbAS+Ve0he3QFbHBlpZtaRVLk74I3A/kAfSTOB8yLiSuBoVn0puS8wUtISsqbkkyKiyRebDZhamVYAAAqJSURBVPLqDjiDlUdOquQ4ImLLPPI1M2uragbuiBjeTPrxTaTdBtzWmufn1VQytNFxHVn3lzOBZ3LK08yszTxyMmIugKQ64Bjg28AE4NMRMTWPPM3MVkeBJgfMramkM/BV4FvAWOCIiJiWR15mZtVQoLidW1PJDGApcDHwL2BnSTs3nIwIr7FkZh1LgSJ3XoF7TPr/ndMGH/6zBODAbWYdSpEWUsgrcE8mC9ClwfpNYGxEzMgpTzOzNitO2M5xrhKyxYK7lewPBe6XdHROeZqZtV2BVgvOq1fJ+U2lS9oA+DNwUx75mpm11VrfHbA5EfG2KpkT0cysnRUpMrVr4JZ0ANniCmZmHUqB4nZu/bgnsepiwRuQLaxwbB55mpmtjiI1BuRV4z6s0XEAcyPivZzyMzNbLQWK254d0MwM3FRiZlY8BYrcDtxmZrg7oJlZ4RSpjTuvkZNmZoVSp8q3lki6StIcSZNL0r4v6TVJE9J2aMm5syRNk/S8pENaLGtbP6SZ2ZqlqmPefwcMayL9oogYnLb7ACRtT7ak2Q7pnksl1Zd7uAO3mRlZU0mlW0si4hGg7LqRJQ4HboqI99MkfNOA3cvd4MBtZkbr6tuSRkgaX7KNqDCbUyRNTE0pvVLapsCrJdfMTGnNcuA2M6N1Ne6IGB0RQ0u20RVkcRmwJTAYmA1c0NayuleJmRn5D3mPiDdK8rocuCcdvgb0L7l0s5TWLNe4zczIfzpuSf1KDj9LtuAMwF3A0ZK6SBoIbAWMK/cs17jNzKhuP25JNwL7A30kzQTOA/aXNJhs7qaXga8DRMQUSTcDU8nW6j05IpaVfX5E40n8OobFS1eZXdCMXh87pdZFsA5o0TOjVjvsvvnu0opjTt/unWo6XMc1bjMz8FwlZmZFU6C47cBtZgZQV6DJShy4zczwJFNmZpYj17jNzChWjduB28wML6RgZlY4rnGbmRWMA7eZWcG4qcTMrGBc4zYzK5gCxW0HbjMzoFCR24HbzIxiDXnvsNO62ockjahwaSRbi/h7sfbykPdiqHQhUlu7+HuxlnLgNjMrGAduM7OCceAuBrdjWlP8vVhL+eWkmVnBuMZtZlYwDtxmZgXjwJ0zScskTZD0T0lPS9orpQ+QNLnRtRdLek1SXUnaRpLuSfdPlXRfyf2L0rMbtmPTuZclTUrbVEk/lLRue37utV0zP9/vSzpT0u/Sz7lLSu8j6eWS+xp+rv+U9A9J26Rz+0u6p9Ez75T0eKO0bST9NT3jWUmjS+6f3+g784l0ruF7OiXle0bp99A6Fo+czN+iiBgMIOkQ4CfAfo0vSv+RfBZ4NZ1/OJ0aCYyJiF+l63YuuW16w7ObcEBEvCWpG9lLrN8Cx1Xh81h1LAO+ClzWxLnpJd+ZrwPfo4mfnaSewG7AAkmDIuKldOrXwEUR8cd03U4ltz0aEYc1kWfp93RD4PfA+sB5bflwli//Rm1f6wP/bubc/sAUsv+Qh5ek9wNmNhxExMTWZBgRC4CTgCMkbdCaey1XFwPfktRS5ancd+ZI4G7gJuDokvTG35lJrSlYRMwhG9xzilSgceBrEQfu/HVNf4I+B1wB/KCZ64YDNwJ3AJ+W1DmlXwJcKelhSWdL2qTkni0b/dm7T1MPjoh3gBnAVlX5RFYN/wLGAsc0ca7h5zodOB24sJlnNHxnbmTlX/YXAX+RdL+kb6WaeYN9Gn1ntmzqwan2Xg9s2LqPZe3BgTt/iyJicERsCwwDrm1ci5G0DnAocGcKsk8AhwBExJ+AQcDlwLbAM5L6plunp2c3bI+WKYdrTu2ruX62pek/Ab7Nqv8dNvxctwROo4n+2pI2IvtFPDYiXgCWSNoRICKuBrYDbiH7S+7xhvZ0sqaS0u/M9LZ9PKslB+52FBGPAX2Avo1OHQL0BCall1T/QUkNKiLejojfR8QxwJPAvq3JV1J3YADwQpsLb601F+jVKG0D4K2Gg4h4EZgAfKHMc+6i6Z/3F9LzZ6TvzABW/s7MioirIuJwYCmwY2sKL2kQWTv8nNbcZ+3DgbsdSdqW7M/PuY1ODQdOjIgBETEAGAgcLGk9SQdKWi/d3x3YkuzP7Erz7AZcSlabb66t1KosvVuYLelAgPR+YRhZ80ipHwFnlnnUfwBN1YqHA8NKvjO7kdq5JQ1raGqTtDHQG3it0rKnv+h+A4wKj9DrkNyrJH9dJU1I+wKOi4hlDa0lKSgPI3uBCEBEvCdpLPAZYHNglKSlZL9or4iIJyUNILWFluR1VUT8Ou0/nJpk6sjazZtrW7f8HAtcIqmhjfr8iJhe2lIWEVMkPQ0MKbmv4ecq4APgxNKHpp/9FsCKboARMSN19dsD+CTwK0mL0+lvR8TrqeKwT6PvzA8j4lY+/J52JquhX0fzbetWYx7ybmZWMG4qMTMrGAduM7OCceA2MysYB24zs4Jx4DYzKxgHbltJySxxkyXd0tCHvI3P+p2kz6f9KyRtX+ba/ZVmTmxlHi9L6lNpejPPOF7SqGrka9YeHLitsYYh+juS9SE+qfRkBZMiNSkiToyIqWUu2R9odeA2Wxs5cFs5jwIfTbXhRyXdBUyVVC/pF5KelDQxTT2KMqMkPS/pz5RMUJTmhx6a9ocpm5v8n5IeSgNKTiKbLW+CpH0k9ZV0W8rjSUl7p3t7S3pQ2bzRV9CKOVgk7S7pMUnPqGSe66R/KuOLks4ruefLksalcv1WUn2jZ35E0r3ps0yWdFQr/43NWs0jJ61JqWb9KeCBlDQE2DGN0BsBzI+Ij6XJi/4u6UFgV2AbYHtgI2AqcFWj5/YlmzBr3/SsDSLibUm/ARZExC/Tdb8nm1N6rKTNgT+RTZx0HtnESiMlfRo4oRUf6zlgn4hYqmwBgR8Dn0vndiebz2Mh8KSke4H3gKOAvSNiiaRLgS8B15Y8cxgwKyI+ncrdoxXlMWsTB25rrHSI/qPAlWRNGOMiYkZK/ySwc0P7NdCDbKa6fYEbI2IZMEvSX5p4/p7AIw3Pioi3mynHJ4DtS4aHr5/mXdmXbB5qIuJeSa2Zf6UHcI2krchm6etccm5MRMwFkHQ72RwhS8nmAHkylaMrq066NAm4QNLPgHtamKHRrCocuK2xFSuhNEhB673SJOCbacrZ0usOrWI56oA9I2JxaaJWb17/HwAPR8RnU/PMX0vONZ77Icg+5zURcVZzD4yIFyQNIZuW94eSHoqIkatTSLOWuI3b2uJPwDdKZqDbWtJHgEeAo1IbeD/ggCbufRzYV9LAdG/DqjzvAt1LrnsQ+GbDgaSGXyaPAF9MaZ9i1alTy+nBh7PkHd/o3MGSNpDUFTgC+DvwEPB5ZUt5kc5vUXqTsoUtFkbE9cAvWHmyKLNcuMZtbXEF2fzPTyurAr9JFuzuAA4ka9v+F/BY4xsj4s3URn67snU25wAHky3Bdaukw8kC9v+Qzaw3kex7+gjZC8zzgRslTQH+QfkpbidKWp72bwZ+TtZUcg5wb6NrxwG3AZsB10fEeIB07YOprEuAk4FXSu7bCfhFymcJ8I0y5TGrCs8OaGZWMG4qMTMrGAduM7OCceA2MysYB24zs4Jx4DYzKxgHbjOzgnHgNjMrmP8PSqKtTlf4uGMAAAAASUVORK5CYII=\n"},"metadata":{"needs_background":"light"}}],"source":["# Evaluation Function\n","\n","def evaluate(model, test_loader, version='title'):\n","    y_pred = []\n","    y_true = []\n","\n","    model.eval()\n","    with torch.no_grad():\n","        for batch_idx, data in enumerate(test_loader, 0): \n","            feats = featurizer.featurize_batch(\n","                        data['input_ids'].detach().cpu().numpy(), \n","                        data['rel_ids'].detach().cpu().numpy(), \n","                        data['pos_ids'].detach().cpu().numpy(), \n","                        padded_len=data['input_ids'].shape[1])\n","        \n","            feats = torch.tensor(feats.reshape(feats.shape[0],-1)).to(device, dtype = torch.float)\n","\n","            glove_feats = glove_batch_features(data['input_ids']).to(device, dtype = torch.float)\n","\n","            output = model(feats, glove_feats)\n","            output = output.cpu().detach().numpy().tolist()\n","            output = np.round(output)\n","            y_pred.extend(output.tolist())\n","            y_true.extend(data['targets'].tolist())\n","    \n","    print('Classification Report:')\n","    print('remember: 1 = BIASED, 0 = UNBIASED')\n","    print(classification_report(y_true, y_pred, labels=[1,0], digits=4))\n","    \n","    cm = confusion_matrix(y_true, y_pred, labels=[1,0])\n","    ax= plt.subplot()\n","    sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n","\n","    ax.set_title('Confusion Matrix')\n","\n","    ax.set_xlabel('Predicted Labels')\n","    ax.set_ylabel('True Labels')\n","\n","    ax.xaxis.set_ticklabels(['BIASED', 'UNBIASED'])\n","    ax.yaxis.set_ticklabels(['BIASED', 'UNBIASED'])\n","    \n","    \n","test_model = Classifier().to(device)\n","optimizer = torch.optim.Adam(params =  test_model.parameters(), lr=1e-5)\n","\n","load_checkpoint(destination_folder + '/features_glove_model_' + dataset + '.pt', test_model, optimizer)\n","evaluate(test_model, test_loader)"]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":["mP0P1_WTBRwZ","AlX3tF90Mx2-","7lAASlTuBVCu","EGk80wOeBXja","UMY_xtSNzaK9","TI8Bp6dkglE7","VLAyQr3jBwMK","DS6kgoITxJWX","W_diGAld7E0G","Qpg0Fayj8x33","yZlEe6OmL4mR"],"provenance":[],"authorship_tag":"ABX9TyOd3eIL7P6o+9t1oPD1vGFv"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"8197e2178b6f42498738c8626364043d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b175c0a4d63f42b79405e8488818231b","IPY_MODEL_790fdcccc3834434bb94f55f67dbc4d6","IPY_MODEL_eeca3ea230224bf49144ac77a4527cdb"],"layout":"IPY_MODEL_b672e8d3053b4968ac59f3328ed462f0"}},"b175c0a4d63f42b79405e8488818231b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_603f4da89d274aa68b96c78bac9929c5","placeholder":"​","style":"IPY_MODEL_2f5ee401a1f64caf86bf0769b858508e","value":""}},"790fdcccc3834434bb94f55f67dbc4d6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0235408599884559b7e988a7771f2793","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5f716b0c436344d4a860cc69221e5401","value":0}},"eeca3ea230224bf49144ac77a4527cdb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2bac1637838a436ca568dcddc9cb3b77","placeholder":"​","style":"IPY_MODEL_a0d6a9f89ea6428e81ef9c073a8c80ba","value":" 0/0 [00:00&lt;?, ?it/s]"}},"b672e8d3053b4968ac59f3328ed462f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"603f4da89d274aa68b96c78bac9929c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f5ee401a1f64caf86bf0769b858508e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0235408599884559b7e988a7771f2793":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"5f716b0c436344d4a860cc69221e5401":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2bac1637838a436ca568dcddc9cb3b77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0d6a9f89ea6428e81ef9c073a8c80ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}