{"cells":[{"cell_type":"markdown","metadata":{"id":"Puz42JkrPPKP"},"source":["This file contains the model architecture that combines BERT with BiLSTM to then predict the labels."]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":195,"status":"ok","timestamp":1663424073254,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"},"user_tz":-60},"id":"stJ3qR3jyCdz"},"outputs":[],"source":["# choose dataset from 'NPOV', 'WNC', 'CrowS-Pairs', 'Stereo', 'Mixed'\n","dataset = 'Mixed'"]},{"cell_type":"markdown","metadata":{"id":"36TPKtUlyE2u"},"source":["# Setting Up"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3824,"status":"ok","timestamp":1663424078871,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"},"user_tz":-60},"id":"_ie3WqcK1DGy","outputId":"f96da23a-6900-46ee-c4b0-f0885145b922"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.22.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.9.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1663424078872,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"},"user_tz":-60},"id":"zpktXTo1PHm6"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import shutil\n","import nltk\n","import sys\n","import matplotlib.pyplot as plt\n","from string import punctuation\n","from transformers import BertTokenizerFast, BertModel \n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1488,"status":"ok","timestamp":1663424080352,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"},"user_tz":-60},"id":"j2HnCcenr2R0","outputId":"cb693f38-44f4-48d8-d096-bd3cba1092c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1663424080352,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"},"user_tz":-60},"id":"XLtIREE2r4GP"},"outputs":[],"source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"]},{"cell_type":"markdown","metadata":{"id":"GIEe7tOE8taX"},"source":["# Model checkpoint"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1663424080353,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"},"user_tz":-60},"id":"-FDWNuxR8wD6"},"outputs":[],"source":["# Save and Load Functions\n","\n","def save_checkpoint(save_path, model, optimizer, valid_loss):\n","\n","    if save_path == None:\n","        return\n","    \n","    state_dict = {'model_state_dict': model.state_dict(),\n","                  'optimizer_state_dict': optimizer.state_dict(),\n","                  'valid_loss': valid_loss}\n","    \n","    torch.save(state_dict, save_path)\n","    print(f'Model saved to ==> {save_path}')\n","\n","\n","def load_checkpoint(load_path, model, optimizer):\n","\n","    if load_path==None:\n","        return\n","    \n","    state_dict = torch.load(load_path, map_location=device)\n","    print(f'Model loaded from <== {load_path}')\n","    \n","    model.load_state_dict(state_dict['model_state_dict'])\n","    optimizer.load_state_dict(state_dict['optimizer_state_dict'])\n","    \n","    return state_dict['valid_loss']"]},{"cell_type":"markdown","metadata":{"id":"hi3Tm-Xj7_R-"},"source":["# Data"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":1134,"status":"ok","timestamp":1663424081481,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"},"user_tz":-60},"id":"wIYvpxLV7-1R"},"outputs":[],"source":["# import datasets\n","source_folder = \"/content/drive/MyDrive/Colab Notebooks/Amplifi Project/Data/Processed Datasets/\"\n","train_df = pd.read_csv(source_folder + dataset + '_train.csv', delimiter=',')\n","val_df = pd.read_csv(source_folder + dataset + '_valid.csv', delimiter=',')\n","test_df = pd.read_csv(source_folder + dataset + '_test.csv', delimiter=',')"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1663424081482,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"},"user_tz":-60},"id":"A59tEk-Y8DLV"},"outputs":[],"source":["target_list = ['label']"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1663424081483,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"},"user_tz":-60},"id":"j5BlKA_-8I4n"},"outputs":[],"source":["# hyperparameters\n","max_len = 200\n","train_batch_size = 16\n","val_batch_size = 16\n","test_batch_size = 16"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1663424081484,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"},"user_tz":-60},"id":"n5uMr5ZG8Ojd"},"outputs":[],"source":["class CustomDataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, df, tokenizer, max_len):\n","        self.tokenizer = tokenizer\n","        self.df = df\n","        self.title = df['text']\n","        self.targets = self.df[target_list].values\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.title)\n","\n","    def __getitem__(self, index):\n","        title = str(self.title[index])\n","        title = \" \".join(title.split())\n","\n","        inputs = self.tokenizer.encode_plus(\n","            title,\n","            None,\n","            add_special_tokens=False,\n","            max_length=self.max_len,\n","            padding='max_length',\n","            return_token_type_ids=True,\n","            truncation=True,\n","            return_attention_mask=True,\n","            return_tensors='pt'\n","        )\n","\n","        return {\n","            'input_ids': inputs['input_ids'].flatten(), # ID of each token in the text\n","            'attention_mask': inputs['attention_mask'].flatten(),\n","            'token_type_ids': inputs[\"token_type_ids\"].flatten(),\n","            'targets': torch.FloatTensor(self.targets[index]).squeeze() #Â Bias (1) and Unbias (0) label --> 1 dimensional: (batch_size,)\n","        }"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":218,"status":"ok","timestamp":1663424081696,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"},"user_tz":-60},"id":"Xyv_VsPV1Hor"},"outputs":[],"source":["tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1663424081697,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"},"user_tz":-60},"id":"hPzrXejK8VcQ"},"outputs":[],"source":["train_dataset = CustomDataset(train_df, tokenizer, max_len)\n","val_dataset = CustomDataset(val_df, tokenizer, max_len)\n","test_dataset = CustomDataset(test_df, tokenizer, max_len)"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1663424081697,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"},"user_tz":-60},"id":"BNEArgtr8Y6Z"},"outputs":[],"source":["train_loader = torch.utils.data.DataLoader(train_dataset, \n","    batch_size=train_batch_size,\n","    shuffle=True,\n","    num_workers=0\n",")\n","\n","val_loader = torch.utils.data.DataLoader(val_dataset, \n","    batch_size=val_batch_size,\n","    shuffle=True,\n","    num_workers=0\n",")\n","\n","test_loader = torch.utils.data.DataLoader(test_dataset, \n","    batch_size=test_batch_size,\n","    shuffle=True,\n","    num_workers=0\n",")"]},{"cell_type":"markdown","metadata":{"id":"5sUGS4XjyMIF"},"source":["# Model"]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1663424081698,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"},"user_tz":-60},"id":"5O_M8MYuw321"},"outputs":[],"source":["class Mixed_Model_1(nn.Module):\n","    def __init__(self):\n","          super(Mixed_Model_1, self).__init__()\n","          self.bert = BertModel.from_pretrained(\"bert-base-uncased\", return_dict=True)\n","          ### New layers:\n","          self.lstm = nn.LSTM(768, 256, batch_first=True,bidirectional=True)\n","          self.linear = nn.Linear(256*2, 1)\n","          \n","\n","    def forward(self, input_ids, attn_mask):\n","          bert_output = self.bert(\n","          input_ids, \n","          attention_mask=attn_mask\n","          ) \n","\n","          # print(bert_output.last_hidden_state.shape)\n","\n","          # sequence_output has the following shape: (batch_size, sequence_length, 768)\n","          lstm_output, (h,c) = self.lstm(bert_output.last_hidden_state) ## extract the 1st token's embeddings\n","          hidden = torch.cat((lstm_output[:,-1, :256],lstm_output[:,0, 256:]),dim=-1)\n","          linear_output = self.linear(hidden.view(-1,256*2)) ### assuming that you are only using the output of the last LSTM cell to perform classification\n","\n","          return torch.squeeze(linear_output, 1)"]},{"cell_type":"markdown","metadata":{"id":"-vtHYRA_ZXvv"},"source":["# Initialise model"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1663424081698,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"},"user_tz":-60},"id":"jY9HArXUBJa3"},"outputs":[],"source":["def loss_fn(outputs, targets):\n","    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2042,"status":"ok","timestamp":1663424083733,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"},"user_tz":-60},"id":"5VMki3hHZaEO","outputId":"062cdaed-943c-41a4-b26f-9b7ff8b7a24f"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["training mixed_model_1_Mixed from scratch\n"]}],"source":["model = Mixed_Model_1()\n","model.to(device)\n","optimizer = torch.optim.Adam(params =  model.parameters(), lr=1e-5)\n","\n","destination_folder = \"/content/drive/MyDrive/Colab Notebooks/Amplifi Project/Saved Models and Checkpoints\"\n","\n","try:\n","  load_checkpoint(destination_folder + '/mixed_model_1_' + dataset + '.pt', model, optimizer) # comment this if you wannt to trainn the model from zero\n","  print('mixed_model_1_' + dataset + '.pt --> loaded')\n","except:\n","  print('training mixed_model_1_' + dataset + ' from scratch')"]},{"cell_type":"markdown","metadata":{"id":"WPrxyRndZ-oT"},"source":["# Training"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1663424083734,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"},"user_tz":-60},"id":"kwSmD3LkeF6i"},"outputs":[],"source":["val_targets=[]\n","val_outputs=[]"]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1663424083735,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"},"user_tz":-60},"id":"5un99X-JZ-W3"},"outputs":[],"source":["def train_model(n_epochs, training_loader, validation_loader, model, \n","                optimizer, destination_folder):\n","   \n","  # initialize tracker for minimum validation loss\n","  best_valid_loss = np.Inf\n","  # best_valid_loss = 0.546463\n","  \n","  try:\n","    best_valid_loss\n","  except:\n","    best_valid_loss = np.Inf\n","   \n"," \n","  for epoch in range(1, n_epochs+1):\n","    train_loss = 0\n","    valid_loss = 0\n","\n","    model.train()\n","    print('############# Epoch {}: Training Start   #############'.format(epoch))\n","    for batch_idx, data in enumerate(training_loader):\n","\n","        if batch_idx % round(len(training_loader)/6) == 0:\n","          print(f'--> epoch: {epoch}/{n_epochs} --- step {batch_idx}/{len(training_loader)}')\n","\n","        ids = data['input_ids'].to(device, dtype = torch.long)\n","        mask = data['attention_mask'].to(device, dtype = torch.long)\n","        targets = data['targets'].to(device, dtype = torch.float)\n","\n","        outputs = model(ids, mask)\n","\n","        optimizer.zero_grad()\n","        loss = loss_fn(outputs, targets)\n","        \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        # train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.item() - train_loss))\n","        train_loss += loss.item()\n","    \n","    print('############# Epoch {}: Training End     #############'.format(epoch))\n","\n","    print('############# Epoch {}: Validation Start   #############'.format(epoch))\n","    ######################    \n","    # validate the model #\n","    ######################\n"," \n","    model.eval()\n","   \n","    with torch.no_grad():\n","      for batch_idx, data in enumerate(validation_loader, 0):\n","            if batch_idx % round(len(validation_loader)/6) == 0:\n","              print(f'--> epoch: {epoch}/{n_epochs} --- step {batch_idx}/{len(validation_loader)}')\n","            \n","            ids = data['input_ids'].to(device, dtype = torch.long)\n","            mask = data['attention_mask'].to(device, dtype = torch.long)\n","            targets = data['targets'].to(device, dtype = torch.float)\n","            outputs = model(ids, mask)\n","\n","            loss = loss_fn(outputs, targets)\n","            # valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.item() - valid_loss))\n","            valid_loss += loss.item()\n","            val_targets.extend(targets.cpu().detach().numpy().tolist())\n","            val_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n","\n","      print('############# Epoch {}: Validation End     #############'.format(epoch))\n","      # calculate average losses\n","      #print('before cal avg train loss', train_loss)\n","      train_loss = train_loss/len(training_loader)\n","      valid_loss = valid_loss/len(validation_loader)\n","      # print training/validation statistics \n","      print('Epoch: {} \\tAvgerage Training Loss: {:.6f} \\tAverage Validation Loss: {:.6f}'.format(\n","            epoch, \n","            train_loss,\n","            valid_loss\n","            ))\n","        \n","      ## TODO: save the model if validation loss has decreased\n","      if valid_loss <= best_valid_loss:\n","        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(best_valid_loss,valid_loss))\n","        # save checkpoint as best model\n","        save_checkpoint(destination_folder + '/mixed_model_1_' + dataset + '.pt', model, optimizer, best_valid_loss)\n","        best_valid_loss = valid_loss\n","\n","    print('############# Epoch {}  Done   #############\\n'.format(epoch))\n","\n","  return model"]},{"cell_type":"markdown","metadata":{"id":"OVUp1Y2mIcUZ"},"source":["## Storage of training and validation losses:\n","- epoch 1: T = 0.579432 | V = 0.554498\n","- epoch 2: T = 0.533245 | V = 0.546463\n","- epoch 3: T = 0.490669 | V = 0.565605"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8IXv2LL8eeS_","executionInfo":{"status":"ok","timestamp":1663425007115,"user_tz":-60,"elapsed":923388,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"}},"outputId":"8b700f57-3fd0-4c8a-a1e4-cd5661020816"},"outputs":[{"output_type":"stream","name":"stdout","text":["############# Epoch 1: Training Start   #############\n","--> epoch: 1/5 --- step 0/500\n","--> epoch: 1/5 --- step 83/500\n","--> epoch: 1/5 --- step 166/500\n","--> epoch: 1/5 --- step 249/500\n","--> epoch: 1/5 --- step 332/500\n","--> epoch: 1/5 --- step 415/500\n","--> epoch: 1/5 --- step 498/500\n","############# Epoch 1: Training End     #############\n","############# Epoch 1: Validation Start   #############\n","--> epoch: 1/5 --- step 0/63\n","--> epoch: 1/5 --- step 10/63\n","--> epoch: 1/5 --- step 20/63\n","--> epoch: 1/5 --- step 30/63\n","--> epoch: 1/5 --- step 40/63\n","--> epoch: 1/5 --- step 50/63\n","--> epoch: 1/5 --- step 60/63\n","############# Epoch 1: Validation End     #############\n","Epoch: 1 \tAvgerage Training Loss: 0.648522 \tAverage Validation Loss: 0.637027\n","Validation loss decreased (inf --> 0.637027).  Saving model ...\n","Model saved to ==> /content/drive/MyDrive/Colab Notebooks/Amplifi Project/Saved Models and Checkpoints/mixed_model_1_Mixed.pt\n","############# Epoch 1  Done   #############\n","\n","############# Epoch 2: Training Start   #############\n","--> epoch: 2/5 --- step 0/500\n","--> epoch: 2/5 --- step 83/500\n","--> epoch: 2/5 --- step 166/500\n","--> epoch: 2/5 --- step 249/500\n","--> epoch: 2/5 --- step 332/500\n","--> epoch: 2/5 --- step 415/500\n","--> epoch: 2/5 --- step 498/500\n","############# Epoch 2: Training End     #############\n","############# Epoch 2: Validation Start   #############\n","--> epoch: 2/5 --- step 0/63\n","--> epoch: 2/5 --- step 10/63\n","--> epoch: 2/5 --- step 20/63\n","--> epoch: 2/5 --- step 30/63\n","--> epoch: 2/5 --- step 40/63\n","--> epoch: 2/5 --- step 50/63\n","--> epoch: 2/5 --- step 60/63\n","############# Epoch 2: Validation End     #############\n","Epoch: 2 \tAvgerage Training Loss: 0.561900 \tAverage Validation Loss: 0.618695\n","Validation loss decreased (0.637027 --> 0.618695).  Saving model ...\n","Model saved to ==> /content/drive/MyDrive/Colab Notebooks/Amplifi Project/Saved Models and Checkpoints/mixed_model_1_Mixed.pt\n","############# Epoch 2  Done   #############\n","\n","############# Epoch 3: Training Start   #############\n","--> epoch: 3/5 --- step 0/500\n","--> epoch: 3/5 --- step 83/500\n","--> epoch: 3/5 --- step 166/500\n","--> epoch: 3/5 --- step 249/500\n","--> epoch: 3/5 --- step 332/500\n","--> epoch: 3/5 --- step 415/500\n","--> epoch: 3/5 --- step 498/500\n","############# Epoch 3: Training End     #############\n","############# Epoch 3: Validation Start   #############\n","--> epoch: 3/5 --- step 0/63\n","--> epoch: 3/5 --- step 10/63\n","--> epoch: 3/5 --- step 20/63\n","--> epoch: 3/5 --- step 30/63\n","--> epoch: 3/5 --- step 40/63\n","--> epoch: 3/5 --- step 50/63\n","--> epoch: 3/5 --- step 60/63\n","############# Epoch 3: Validation End     #############\n","Epoch: 3 \tAvgerage Training Loss: 0.449238 \tAverage Validation Loss: 0.655048\n","############# Epoch 3  Done   #############\n","\n","############# Epoch 4: Training Start   #############\n","--> epoch: 4/5 --- step 0/500\n","--> epoch: 4/5 --- step 83/500\n","--> epoch: 4/5 --- step 166/500\n","--> epoch: 4/5 --- step 249/500\n","--> epoch: 4/5 --- step 332/500\n","--> epoch: 4/5 --- step 415/500\n","--> epoch: 4/5 --- step 498/500\n","############# Epoch 4: Training End     #############\n","############# Epoch 4: Validation Start   #############\n","--> epoch: 4/5 --- step 0/63\n","--> epoch: 4/5 --- step 10/63\n","--> epoch: 4/5 --- step 20/63\n","--> epoch: 4/5 --- step 30/63\n","--> epoch: 4/5 --- step 40/63\n","--> epoch: 4/5 --- step 50/63\n","--> epoch: 4/5 --- step 60/63\n","############# Epoch 4: Validation End     #############\n","Epoch: 4 \tAvgerage Training Loss: 0.307403 \tAverage Validation Loss: 0.793332\n","############# Epoch 4  Done   #############\n","\n","############# Epoch 5: Training Start   #############\n","--> epoch: 5/5 --- step 0/500\n","--> epoch: 5/5 --- step 83/500\n","--> epoch: 5/5 --- step 166/500\n","--> epoch: 5/5 --- step 249/500\n","--> epoch: 5/5 --- step 332/500\n","--> epoch: 5/5 --- step 415/500\n","--> epoch: 5/5 --- step 498/500\n","############# Epoch 5: Training End     #############\n","############# Epoch 5: Validation Start   #############\n","--> epoch: 5/5 --- step 0/63\n","--> epoch: 5/5 --- step 10/63\n","--> epoch: 5/5 --- step 20/63\n","--> epoch: 5/5 --- step 30/63\n","--> epoch: 5/5 --- step 40/63\n","--> epoch: 5/5 --- step 50/63\n","--> epoch: 5/5 --- step 60/63\n","############# Epoch 5: Validation End     #############\n","Epoch: 5 \tAvgerage Training Loss: 0.202396 \tAverage Validation Loss: 1.004322\n","############# Epoch 5  Done   #############\n","\n"]}],"source":["epochs = 5\n","trained_model = train_model(epochs, train_loader, val_loader, model, optimizer, destination_folder)"]},{"cell_type":"markdown","metadata":{"id":"DTtYgrC5AjWv"},"source":["# Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"3vY_50klAkbw","outputId":"a93f2a09-e907-4d7f-f4ad-8144356ccf91"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Model loaded from <== /content/drive/MyDrive/Colab Notebooks/Amplifi Project/Saved Models and Checkpoints/mixed_model_1.pt\n","accuracy = 71.35654857016915 %\n"]}],"source":["# testing\n","corrects = 0\n","totals = 0\n","\n","test_model = Mixed_Model_1()\n","test_model.to(device)\n","# optimizer = torch.optim.Adam([\n","#                 {'params': test_model.bert.parameters()},\n","#                 {'params': test_model.bilstm.parameters(), 'lr': 0.001}\n","#             ], lr=1e-5)\n","optimizer = torch.optim.Adam(params =  test_model.parameters(), lr=1e-5)\n","destination_folder = \"/content/drive/MyDrive/Colab Notebooks/Amplifi Project/Saved Models and Checkpoints/\"\n","load_checkpoint(destination_folder + '/mixed_model_1_' + dataset + '.pt', test_model, optimizer)\n","\n","with torch.no_grad():\n","  test_model.eval() \n","  for batch_idx, data in enumerate(test_loader, 0): \n","    input_ids = data['input_ids'].to(device, dtype=torch.long)\n","    attention_mask = data['attention_mask'].to(device, dtype=torch.long)\n","    output = test_model(input_ids, attention_mask)\n","    final_output = torch.sigmoid(output).cpu().detach().numpy().tolist()\n","    pred_class = np.round(final_output)\n","    corrects += np.count_nonzero((data['targets'] - pred_class) == 0.)\n","    totals += len(pred_class)\n","  \n","  # Calculate accuracy of test set\n","  acc = corrects / totals\n","\n","  print(f'accuracy = {acc * 100} %')"]},{"cell_type":"markdown","metadata":{"id":"T7VjBC51yu9_"},"source":["# Evaluation"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":583},"id":"Ubq79maOyjb-","executionInfo":{"status":"ok","timestamp":1663425017946,"user_tz":-60,"elapsed":10849,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"}},"outputId":"4c9b0a3b-03a3-4f49-8d2c-e8a84ff053d1"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Model loaded from <== /content/drive/MyDrive/Colab Notebooks/Amplifi Project/Saved Models and Checkpoints/mixed_model_1_Mixed.pt\n","Classification Report:\n","remember: 1 = BIASED, 0 = UNBIASED\n","              precision    recall  f1-score   support\n","\n","           1     0.7619    0.6095    0.6772       525\n","           0     0.6466    0.7895    0.7109       475\n","\n","    accuracy                         0.6950      1000\n","   macro avg     0.7042    0.6995    0.6941      1000\n","weighted avg     0.7071    0.6950    0.6932      1000\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["# Evaluation Function\n","\n","def evaluate(model, test_loader, threshold=0.5):\n","    y_pred = []\n","    y_true = []\n","\n","    model.eval()\n","    with torch.no_grad():\n","        for data in test_loader:           \n","            labels = data['targets'].to(device)\n","            input_ids = data['input_ids'].to(device, dtype=torch.long)\n","            attention_mask = data['attention_mask'].to(device, dtype=torch.long)\n","            output = model(input_ids, attention_mask)\n","            output = torch.sigmoid(output).cpu().detach().numpy().tolist()\n","            output = np.round(output)\n","            y_pred.extend(output.tolist())\n","            y_true.extend(labels.tolist())\n","    \n","    print('Classification Report:')\n","    print('remember: 1 = BIASED, 0 = UNBIASED')\n","    print(classification_report(y_true, y_pred, labels=[1,0], digits=4))\n","    \n","    cm = confusion_matrix(y_true, y_pred, labels=[1,0])\n","    ax= plt.subplot()\n","    sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n","\n","    ax.set_title('Confusion Matrix')\n","\n","    ax.set_xlabel('Predicted Labels')\n","    ax.set_ylabel('True Labels')\n","\n","    ax.xaxis.set_ticklabels(['BIASED', 'UNBIASED'])\n","    ax.yaxis.set_ticklabels(['BIASED', 'UNBIASED'])\n","    \n","    \n","best_model = Mixed_Model_1().to(device)\n","optimizer = optim.Adam(best_model.parameters(), lr=1e-5)\n","\n","destination_folder = \"/content/drive/MyDrive/Colab Notebooks/Amplifi Project/Saved Models and Checkpoints\"\n","load_checkpoint(destination_folder + '/mixed_model_1_' + dataset + '.pt', best_model, optimizer)\n","evaluate(best_model, test_loader)"]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":["36TPKtUlyE2u","GIEe7tOE8taX","hi3Tm-Xj7_R-"],"machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyN0LQc0YETrYatPGIX37Lxr"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}