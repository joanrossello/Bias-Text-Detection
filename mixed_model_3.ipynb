{"cells":[{"cell_type":"markdown","metadata":{"id":"I-N3sridqmq1"},"source":["This file contains the model architecture that combines BERT and tags to then predict the labels. In this case we work with only 2 dimensions (batch size and features) insetad of 3 dimensions (i.e. including sequence length). We do not use a GCN yet."]},{"cell_type":"code","source":["# choose dataset from 'NPOV', 'WNC', 'CrowS-Pairs', 'Stereo', 'Mixed'\n","dataset = 'Mixed'"],"metadata":{"id":"KpgjllVVzF1h","executionInfo":{"status":"ok","timestamp":1663374058205,"user_tz":-60,"elapsed":412,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"}}},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":["# Setting Up"],"metadata":{"id":"0ihgV4BqzGmD"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19765,"status":"ok","timestamp":1663372647087,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"},"user_tz":-60},"id":"p4P3R-duqcYI","outputId":"2e1d7c8b-c9b9-4e48-b6e2-ce14bd147d9a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.22.1-py3-none-any.whl (4.9 MB)\n","\u001b[K     |████████████████████████████████| 4.9 MB 12.3 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Collecting huggingface-hub<1.0,>=0.9.0\n","  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n","\u001b[K     |████████████████████████████████| 120 kB 55.6 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 51.9 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.22.1\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"RgBbxurjAB02","colab":{"base_uri":"https://localhost:8080/","height":0,"referenced_widgets":["541861263f704bcb810158fc098adff6","740a763932ed4423b8d03b88c856d6e6","4396614da47540b3857f656e148eec21","049ddf865425425bb0b0ae2f95ee8524","54e5cebeda5a407bbc893b3acdaf9b60","2f84b3b5ca62463f9184d66dbb3cfe49","9b8cbc25a9584669924b1b37dfb3a72e","dec18f9dd81f4e3ba0d2df06b1a20435","c21929cb23fd4afa87ee2bde1aa4a598","15fbfc6c948b4f379def1414a129e707","58d7ce73f72c4d3487fac82b4499ccf7"]},"executionInfo":{"status":"ok","timestamp":1663372671956,"user_tz":-60,"elapsed":24877,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"}},"outputId":"336435b0-8aa3-4b1f-fe00-be615b295b23"},"outputs":[{"output_type":"stream","name":"stderr","text":["The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"]},{"output_type":"stream","name":"stdout","text":["Moving 0 files to the new cache system\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"541861263f704bcb810158fc098adff6"}},"metadata":{}}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import shutil\n","import nltk\n","import sys\n","import matplotlib.pyplot as plt\n","from string import punctuation\n","from transformers import BertTokenizerFast, BertModel \n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","import nltk\n","from nltk.parse.stanford import StanfordDependencyParser\n","\n","import sys; sys.path.append('.')\n","\n","import spacy\n","nlp = spacy.load(\"en_core_web_sm\")"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20263,"status":"ok","timestamp":1663372692202,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"},"user_tz":-60},"id":"07kIbIjyAOZ4","outputId":"0c15a6b8-ef6c-48cf-9b5b-f3630daea994"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"4cTMr7-0AQfU","executionInfo":{"status":"ok","timestamp":1663372692203,"user_tz":-60,"elapsed":13,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"}}},"outputs":[],"source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"]},{"cell_type":"markdown","metadata":{"id":"XcLwaiiqAUbf"},"source":["# Model Checkpoint"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"gUwDjLlSAUKp","executionInfo":{"status":"ok","timestamp":1663372692203,"user_tz":-60,"elapsed":11,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"}}},"outputs":[],"source":["# Save and Load Functions\n","\n","def save_checkpoint(save_path, model, optimizer, valid_loss):\n","\n","    if save_path == None:\n","        return\n","    \n","    state_dict = {'model_state_dict': model.state_dict(),\n","                  'optimizer_state_dict': optimizer.state_dict(),\n","                  'valid_loss': valid_loss}\n","    \n","    torch.save(state_dict, save_path)\n","    print(f'Model saved to ==> {save_path}')\n","\n","\n","def load_checkpoint(load_path, model, optimizer):\n","\n","    if load_path==None:\n","        return\n","    \n","    state_dict = torch.load(load_path, map_location=device)\n","    print(f'Model loaded from <== {load_path}')\n","    \n","    model.load_state_dict(state_dict['model_state_dict'])\n","    optimizer.load_state_dict(state_dict['optimizer_state_dict'])\n","    \n","    return state_dict['valid_loss']"]},{"cell_type":"markdown","metadata":{"id":"wxg4JvvNO2QZ"},"source":["# Tags"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"hMzQlDhjO4zL","executionInfo":{"status":"ok","timestamp":1663372692204,"user_tz":-60,"elapsed":12,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"}}},"outputs":[],"source":["# Dependency parser: https://spacy.io/api/dependencyparser\n","# https://www.upgrad.com/blog/dependency-parsing-in-nlp/ \n","RELATIONS = ['<PAD>',\n","    'ROOT', 'acl', 'acomp', 'advcl', 'advmod', 'agent', 'amod', 'appos', \n","    'aux', 'auxpass', 'case', 'cc', 'ccomp', 'compound', 'conj', 'csubj', \n","    'dative', 'dep', 'det', 'dobj', 'expl', 'intj', 'mark', 'meta', 'neg',\n","    'nmod', 'npadvmod', 'nsubj', 'nsubjpass', 'nummod', 'oprd', 'parataxis',\n","    'pcomp', 'pobj', 'poss', 'preconj', 'predet', 'prep', 'prt', 'punct',\n","    'quantmod', 'relcl', 'xcomp', 'attr', 'csubjpass',\n","    '<UNK>'\n","]\n","REL2ID = {x: i for i, x in enumerate(RELATIONS)}\n","\n","# Part-Of-Speech tagging: https://spacy.io/usage/linguistic-features#pos-tagging \n","POS_TAGS = ['<PAD>',\n","    'ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'CONJ', 'DET', 'EOL',\n","    'IDS', 'INTJ', 'NAMES', 'NOUN', 'NO_TAG', 'NUM', 'PART',\n","    'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SPACE', 'SYM', 'VERB', 'X',\n","    '<UNK>'\n","]\n","POS2ID = {x: i for i, x in enumerate(POS_TAGS)} "]},{"cell_type":"markdown","metadata":{"id":"ksTMDIVhAbQi"},"source":["# Data"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"k8bepgQ_AcGe","executionInfo":{"status":"ok","timestamp":1663374064366,"user_tz":-60,"elapsed":1929,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"}}},"outputs":[],"source":["# import datasets\n","source_folder = \"/content/drive/MyDrive/Colab Notebooks/Amplifi Project/Data/Processed Datasets/\"\n","train_df = pd.read_csv(source_folder + dataset + '_train.csv', delimiter=',')\n","val_df = pd.read_csv(source_folder + dataset + '_valid.csv', delimiter=',')\n","test_df = pd.read_csv(source_folder + dataset + '_test.csv', delimiter=',')"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"zrshzBAKAkNY","executionInfo":{"status":"ok","timestamp":1663374064366,"user_tz":-60,"elapsed":11,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"}}},"outputs":[],"source":["# hyperparameters\n","max_len = 200 # we cap the max length at 200, even though some data samples have larger length\n","train_batch_size = 16\n","val_batch_size = 16\n","test_batch_size = 16\n","\n","target_list = ['label']"]},{"cell_type":"code","execution_count":45,"metadata":{"id":"Yq8VPPt7AkvW","executionInfo":{"status":"ok","timestamp":1663374064367,"user_tz":-60,"elapsed":11,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"}}},"outputs":[],"source":["class CustomDataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, df, tokenizer, max_len):\n","        self.tokenizer = tokenizer\n","        self.df = df\n","        self.title = df['text']\n","        self.pos = df['pos_tags']\n","        self.rel = df['rel_tags']\n","        self.targets = self.df[target_list].values\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.title)\n","\n","    def __getitem__(self, index):\n","        title = str(self.title[index])\n","        title = \" \".join(title.split())\n","\n","        pos_str = str(self.pos[index])\n","        pos = []\n","        for tag in pos_str.split():\n","          try:\n","            pos.append(POS2ID[tag])\n","          except:\n","            POS2ID['<UNK>']\n","        pos = torch.tensor(pos)\n","        pos_ids = torch.zeros(max_len, dtype=int)\n","        if len(pos) > max_len:\n","          pos_ids[:] = pos[:max_len]\n","        else:\n","          pos_ids[:len(pos)] = pos\n","          # pos_ids[(max_len - len(pos)):] = pos\n","\n","        rel_str = str(self.rel[index])\n","        rel = []\n","        for tag in rel_str.split():\n","          try:\n","            rel.append(REL2ID[tag])\n","          except:\n","            REL2ID['<UNK>']\n","        rel = torch.tensor(rel)\n","        rel_ids = torch.zeros(max_len, dtype=int)\n","        if len(rel) > max_len:\n","          rel_ids[:] = rel[:max_len]\n","        else:\n","          rel_ids[:len(rel)] = rel\n","          # rel_ids[(max_len - len(rel)):] = rel\n","\n","        inputs = self.tokenizer.encode_plus(\n","            title,\n","            None,\n","            add_special_tokens=False, # we do not want SOS and EOS tokens\n","            max_length=self.max_len,\n","            padding='max_length',\n","            return_token_type_ids=False, # we cannot have this if we do not have SOS and EOS tokens\n","            truncation=True,\n","            return_attention_mask=True,\n","            return_tensors='pt'\n","        )\n","\n","        return {\n","            'text': title,\n","            'input_ids': inputs['input_ids'].flatten(), # ID of each token in the text\n","            'pos_ids': pos_ids,\n","            'rel_ids': rel_ids,\n","            'attention_mask': inputs['attention_mask'].flatten(),\n","            # 'token_type_ids': inputs[\"token_type_ids\"].flatten(),\n","            'targets': torch.FloatTensor(self.targets[index]) # Bias and Unbias label (0 when False, 1 when True)\n","        }"]},{"cell_type":"code","execution_count":46,"metadata":{"executionInfo":{"elapsed":488,"status":"ok","timestamp":1663374064845,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"},"user_tz":-60},"id":"2YvO5B1ABIK6"},"outputs":[],"source":["tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"]},{"cell_type":"code","execution_count":47,"metadata":{"id":"pBVaMl9yArU_","executionInfo":{"status":"ok","timestamp":1663374064846,"user_tz":-60,"elapsed":7,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"}}},"outputs":[],"source":["train_dataset = CustomDataset(train_df, tokenizer, max_len)\n","val_dataset = CustomDataset(val_df, tokenizer, max_len)\n","test_dataset = CustomDataset(test_df, tokenizer, max_len)"]},{"cell_type":"code","execution_count":48,"metadata":{"id":"4sJpJuw1AwZG","executionInfo":{"status":"ok","timestamp":1663374064846,"user_tz":-60,"elapsed":6,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"}}},"outputs":[],"source":["train_loader = torch.utils.data.DataLoader(train_dataset, \n","    batch_size=train_batch_size,\n","    shuffle=True,\n","    num_workers=0\n",")\n","\n","val_loader = torch.utils.data.DataLoader(val_dataset, \n","    batch_size=val_batch_size,\n","    shuffle=False,\n","    num_workers=0\n",")\n","\n","test_loader = torch.utils.data.DataLoader(test_dataset, \n","    batch_size=test_batch_size,\n","    shuffle=False,\n","    num_workers=0\n",")"]},{"cell_type":"markdown","metadata":{"id":"KRYjD4p5BV5R"},"source":["# Featurizer"]},{"cell_type":"code","execution_count":49,"metadata":{"id":"7vPTST10Bc_B","executionInfo":{"status":"ok","timestamp":1663374065206,"user_tz":-60,"elapsed":366,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"}}},"outputs":[],"source":["class Featurizer:\n","\n","    def __init__(self, tok2id={}, pad_id=0, lexicon_feature_bits=1):\n","        self.tok2id = tok2id\n","        self.id2tok = {x: tok for tok, x in tok2id.items()}\n","        self.pad_id = pad_id\n","\n","        self.pos2id = POS2ID\n","        self.rel2id = REL2ID\n","\n","        self.lexicons = {\n","            'assertives': self.read_lexicon('/content/drive/MyDrive/Colab Notebooks/Amplifi Project/lexicons/assertives_hooper1975.txt'),\n","            'entailed_arg': self.read_lexicon('/content/drive/MyDrive/Colab Notebooks/Amplifi Project/lexicons/entailed_arg_berant2012.txt'),\n","            'entailed': self.read_lexicon('/content/drive/MyDrive/Colab Notebooks/Amplifi Project/lexicons/entailed_berant2012.txt'), \n","            'entailing_arg': self.read_lexicon('/content/drive/MyDrive/Colab Notebooks/Amplifi Project/lexicons/entailing_arg_berant2012.txt'), \n","            'entailing': self.read_lexicon('/content/drive/MyDrive/Colab Notebooks/Amplifi Project/lexicons/entailing_berant2012.txt'), \n","            'factives': self.read_lexicon('/content/drive/MyDrive/Colab Notebooks/Amplifi Project/lexicons/factives_hooper1975.txt'),\n","            'hedges': self.read_lexicon('/content/drive/MyDrive/Colab Notebooks/Amplifi Project/lexicons/hedges_hyland2005.txt'),\n","            'implicatives': self.read_lexicon('/content/drive/MyDrive/Colab Notebooks/Amplifi Project/lexicons/implicatives_karttunen1971.txt'),\n","            'negatives': self.read_lexicon('/content/drive/MyDrive/Colab Notebooks/Amplifi Project/lexicons/negative_liu2005.txt'),\n","            'positives': self.read_lexicon('/content/drive/MyDrive/Colab Notebooks/Amplifi Project/lexicons/positive_liu2005.txt'),\n","            'npov': self.read_lexicon('/content/drive/MyDrive/Colab Notebooks/Amplifi Project/lexicons/npov_lexicon.txt'),\n","            'reports': self.read_lexicon('/content/drive/MyDrive/Colab Notebooks/Amplifi Project/lexicons/report_verbs.txt'),\n","            'strong_subjectives': self.read_lexicon('/content/drive/MyDrive/Colab Notebooks/Amplifi Project/lexicons/strong_subjectives_riloff2003.txt'),\n","            'weak_subjectives': self.read_lexicon('/content/drive/MyDrive/Colab Notebooks/Amplifi Project/lexicons/weak_subjectives_riloff2003.txt')\n","        }\n","        self.lexicon_feature_bits = lexicon_feature_bits\n","\n","\n","    def get_feature_names(self):\n","\n","        lexicon_feature_names = list(self.lexicons.keys())\n","        context_feature_names = [x + '_context' for x in lexicon_feature_names]\n","        pos_names = list(list(zip(*sorted(self.pos2id.items(), key=lambda x: x[1])))[0])\n","        rel_names = list(list(zip(*sorted(self.rel2id.items(), key=lambda x: x[1])))[0])\n","\n","        return lexicon_feature_names + context_feature_names + pos_names + rel_names        \n","\n","    def read_lexicon(self, fp):\n","        out = set([\n","            l.strip() for l in open(fp, errors='ignore') \n","            if not l.startswith('#') and not l.startswith(';')\n","            and len(l.strip().split()) == 1\n","        ])\n","        return out\n","\n","\n","    def lexicon_features(self, words, bits=2):\n","        assert bits in [1, 2]\n","        if bits == 1:\n","            true = 1\n","            false = 0\n","        else:\n","            true = [1, 0]\n","            false = [0, 1]\n","    \n","        out = []\n","        for word in words:\n","            out.append([\n","                true if word in lexicon else false \n","                for _, lexicon in self.lexicons.items()\n","            ])\n","        out = np.array(out)\n","\n","        if bits == 2:\n","            out = out.reshape(len(words), -1)\n","\n","        return out\n","\n","\n","    def context_features(self, lex_feats, window_size=2):\n","        out = []\n","        nwords = lex_feats.shape[0]\n","        nfeats = lex_feats.shape[1]\n","        for wi in range(lex_feats.shape[0]):\n","            window_start = max(wi - window_size, 0)\n","            window_end = min(wi + window_size + 1, nwords)\n","\n","            left = lex_feats[window_start: wi, :] if wi > 0 else np.zeros((1, nfeats))\n","            right = lex_feats[wi + 1: window_end, :] if wi < nwords - 1 else np.zeros((1, nfeats))\n","\n","            out.append((np.sum(left + right, axis=0) > 0).astype(int))\n","\n","        return np.array(out)\n","\n","\n","    def features(self, id_seq, rel_ids, pos_ids):\n","        if self.pad_id in id_seq:\n","            pad_idx = id_seq.index(self.pad_id)\n","            pad_len = len(id_seq[pad_idx:])\n","            id_seq = id_seq[:pad_idx]\n","            rel_ids = rel_ids[:pad_idx]\n","            pos_ids = pos_ids[:pad_idx]\n","        else:\n","            pad_len = 0\n","\n","        toks = [self.id2tok[x] for x in id_seq]\n","        # build list of [word, [tok indices the word came from]]\n","        words = []\n","        word_indices = []\n","        for i, tok in enumerate(toks):\n","            if tok.startswith('##'):\n","                words[-1] += tok.replace('##', '')\n","                word_indices[-1].append(i)\n","            else:\n","                words.append(tok)\n","                word_indices.append([i])\n","\n","        # get expert features\n","        lex_feats = self.lexicon_features(words, bits=self.lexicon_feature_bits)\n","        context_feats = self.context_features(lex_feats)\n","        expert_feats = np.concatenate((lex_feats, context_feats), axis=1)\n","        # break word-features into tokens\n","        feats = np.concatenate([\n","            np.repeat(np.expand_dims(word_vec, axis=0), len(indices), axis=0) \n","            for (word_vec, indices) in zip(expert_feats, word_indices)\n","        ], axis=0)\n","\n","        # add in the pos and relational features\n","        pos_feats = np.zeros((len(pos_ids), len(POS2ID)))\n","        pos_feats[range(len(pos_ids)), pos_ids] = 1\n","        rel_feats = np.zeros((len(rel_ids), len(REL2ID)))\n","        rel_feats[range(len(rel_ids)), rel_ids] = 1\n","        \n","        feats = np.concatenate((feats, pos_feats, rel_feats), axis=1)\n","\n","        # add pad back in                \n","        feats = np.concatenate((feats, np.zeros((pad_len, feats.shape[1]))))\n","\n","        return feats\n","\n","\n","    def featurize_batch(self, batch_ids, rel_ids, pos_ids, padded_len=0):\n","        \"\"\" takes [batch, len] returns [batch, len, features] --> i.e. for every sentence in the batch, for every word in len we have the features\"\"\"\n","\n","        batch_feats = [\n","            self.features(list(id_seq), list(rel_ids), list(pos_ids)) \n","            for id_seq, rel_ids, pos_ids in zip(batch_ids, rel_ids, pos_ids)]\n","        batch_feats = np.array(batch_feats)\n","        return batch_feats\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"m8HK9QreBTz1"},"source":["# Model Class"]},{"cell_type":"code","execution_count":50,"metadata":{"id":"16kx-n-9DjGA","executionInfo":{"status":"ok","timestamp":1663374065206,"user_tz":-60,"elapsed":8,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"}}},"outputs":[],"source":["# number of features (len of X cols)\n","feat_feats = 20000\n","# hidden layers\n","hidden_layer1 = 10000\n","hidden_layer2 = 768\n","# bert features\n","bert_feats = 768\n","# lstm features\n","lstm_feats = 256\n","# number of classes (unique of y)\n","output_dim = 1\n","# dropout ratio\n","drop = 0.3"]},{"cell_type":"code","execution_count":51,"metadata":{"id":"ejmXNQB-A3zs","executionInfo":{"status":"ok","timestamp":1663374065207,"user_tz":-60,"elapsed":8,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"}}},"outputs":[],"source":["class Mixed_Model_3(nn.Module):\n","    def __init__(self):\n","          super(Mixed_Model_3, self).__init__()\n","          self.bert = BertModel.from_pretrained(\"bert-base-uncased\", return_dict=True)\n","          self.linear1 = nn.Linear(feat_feats, hidden_layer1)\n","          self.linear2 = nn.Linear(hidden_layer1, hidden_layer2)\n","          self.linear3 = nn.Linear(bert_feats + hidden_layer2, bert_feats)\n","          self.linear4 = nn.Linear(bert_feats, output_dim)\n","          self.dropout = torch.nn.Dropout(drop)\n","          \n","\n","    def forward(self, feats, input_ids, attn_mask):\n","          bert_output = self.bert(\n","          input_ids, \n","          attention_mask=attn_mask,\n","          ) \n","\n","          feats_output = self.dropout(torch.sigmoid(self.linear1(feats)))\n","          feats_output = self.dropout(torch.sigmoid(self.linear2(feats_output)))\n","\n","          out1 = feats_output # shape [batch, 768]\n","          out2 = bert_output.pooler_output # shape [batch, 768]\n","\n","          out = torch.concat((out1, out2), axis=1) # shape [batch, 1536]\n","\n","          linear_output = self.dropout(torch.sigmoid(self.linear3(out)))\n","          linear_output = self.linear4(linear_output)\n","\n","          return linear_output"]},{"cell_type":"markdown","metadata":{"id":"EcVTnZdBGXnv"},"source":["# Initialise model"]},{"cell_type":"code","execution_count":52,"metadata":{"id":"immax5qfGd8x","executionInfo":{"status":"ok","timestamp":1663374066605,"user_tz":-60,"elapsed":5,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"}}},"outputs":[],"source":["def loss_fn(outputs, targets):\n","    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"]},{"cell_type":"code","execution_count":53,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5581,"status":"ok","timestamp":1663374072182,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"},"user_tz":-60},"id":"7yi5O69mGekn","outputId":"0ed29c31-25fd-4d8b-b9bd-b0c21adfbbc1"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["training mixed_model_3_Mixed from scratch\n"]}],"source":["model = Mixed_Model_3()\n","model.to(device)\n","optimizer = torch.optim.Adam(params =  model.parameters(), lr=1e-5)\n","\n","destination_folder = \"/content/drive/MyDrive/Colab Notebooks/Amplifi Project/Saved Models and Checkpoints\"\n","\n","try:\n","  load_checkpoint(destination_folder + '/mixed_model_3_' + dataset + '.pt', model, optimizer) # comment this if you wannt to trainn the model from zero\n","  print('mixed_model_3_' + dataset + '.pt --> loaded')\n","except:\n","  print('training mixed_model_3_' + dataset + ' from scratch')"]},{"cell_type":"markdown","metadata":{"id":"qclx9wcHFe4A"},"source":["# Training"]},{"cell_type":"code","execution_count":54,"metadata":{"id":"dYXkM5vIFf5s","executionInfo":{"status":"ok","timestamp":1663374072183,"user_tz":-60,"elapsed":10,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"}}},"outputs":[],"source":["val_targets=[]\n","val_outputs=[]"]},{"cell_type":"code","execution_count":55,"metadata":{"id":"V8f-LiAHFhkN","executionInfo":{"status":"ok","timestamp":1663374072183,"user_tz":-60,"elapsed":7,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"}}},"outputs":[],"source":["def train_model(n_epochs, featurizer, training_loader, validation_loader, model, \n","                optimizer, destination_folder):\n","   \n","  # initialize tracker for minimum validation loss\n","  best_valid_loss = np.Inf\n"," \n","  for epoch in range(1, n_epochs+1):\n","    train_loss = 0\n","    valid_loss = 0\n","\n","    model.train()\n","    print('############# Epoch {}: Training Start   #############'.format(epoch))\n","    for batch_idx, data in enumerate(training_loader):\n","\n","        if batch_idx % round(len(training_loader)/6) == 0:\n","          print(f'--> epoch: {epoch}/{n_epochs} --- step {batch_idx}/{len(training_loader)}')\n","\n","        ids = data['input_ids'].to(device, dtype = torch.long)\n","        mask = data['attention_mask'].to(device, dtype = torch.long)\n","        targets = data['targets'].to(device, dtype = torch.float)\n","\n","        feats = featurizer.featurize_batch(\n","                data['input_ids'].detach().cpu().numpy(), \n","                data['rel_ids'].detach().cpu().numpy(), \n","                data['pos_ids'].detach().cpu().numpy(), \n","                padded_len=data['input_ids'].shape[1])\n","\n","        feats = torch.tensor(feats.reshape(feats.shape[0],-1)).to(device, dtype = torch.float)\n","\n","        outputs = model(feats, ids, mask)\n","\n","        optimizer.zero_grad()\n","        loss = loss_fn(outputs, targets)\n","        \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        # train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.item() - train_loss))\n","        train_loss += loss.item()\n","    \n","    print('############# Epoch {}: Training End     #############'.format(epoch))\n","\n","    print('############# Epoch {}: Validation Start   #############'.format(epoch))\n","    ######################    \n","    # validate the model #\n","    ######################\n"," \n","    model.eval()\n","   \n","    with torch.no_grad():\n","      for batch_idx, data in enumerate(validation_loader, 0):\n","            if batch_idx % round(len(validation_loader)/6) == 0:\n","              print(f'--> epoch: {epoch}/{n_epochs} --- step {batch_idx}/{len(validation_loader)}')\n","            \n","            ids = data['input_ids'].to(device, dtype = torch.long)\n","            mask = data['attention_mask'].to(device, dtype = torch.long)\n","            targets = data['targets'].to(device, dtype = torch.float)\n","\n","            feats = featurizer.featurize_batch(\n","                data['input_ids'].detach().cpu().numpy(), \n","                data['rel_ids'].detach().cpu().numpy(), \n","                data['pos_ids'].detach().cpu().numpy(), \n","                padded_len=data['input_ids'].shape[1])\n","\n","            feats = torch.tensor(feats.reshape(feats.shape[0],-1)).to(device, dtype = torch.float)\n","        \n","            outputs = model(feats, ids, mask)\n","\n","            loss = loss_fn(outputs, targets)\n","            # valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.item() - valid_loss))\n","            valid_loss += loss.item()\n","            val_targets.extend(targets.cpu().detach().numpy().tolist())\n","            val_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n","\n","      print('############# Epoch {}: Validation End     #############'.format(epoch))\n","      # calculate average losses\n","      #print('before cal avg train loss', train_loss)\n","      train_loss = train_loss/len(training_loader)\n","      valid_loss = valid_loss/len(validation_loader)\n","      # print training/validation statistics \n","      print('Epoch: {} \\tAvgerage Training Loss: {:.6f} \\tAverage Validation Loss: {:.6f}'.format(\n","            epoch, \n","            train_loss,\n","            valid_loss\n","            ))\n","        \n","      ## TODO: save the model if validation loss has decreased\n","      if valid_loss <= best_valid_loss:\n","        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(best_valid_loss,valid_loss))\n","        # save checkpoint as best model\n","        save_checkpoint(destination_folder + '/mixed_model_3_' + dataset + '.pt', model, optimizer, best_valid_loss)\n","        best_valid_loss = valid_loss\n","\n","    print('############# Epoch {}  Done   #############\\n'.format(epoch))\n","\n","  return model"]},{"cell_type":"code","execution_count":56,"metadata":{"id":"ANlbG-1KG0ld","executionInfo":{"status":"ok","timestamp":1663374072184,"user_tz":-60,"elapsed":8,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"}}},"outputs":[],"source":["tok2id = tokenizer.vocab\n","tok2id['<del>'] = len(tok2id)\n","lexicon_feature_bits = 1\n","featurizer = Featurizer(tok2id, lexicon_feature_bits=lexicon_feature_bits)"]},{"cell_type":"code","execution_count":57,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lQPLOWAtG1JK","outputId":"2d6c4465-dc1c-4894-e1f8-d9b5b25fe360","executionInfo":{"status":"ok","timestamp":1663374699705,"user_tz":-60,"elapsed":627528,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["############# Epoch 1: Training Start   #############\n","--> epoch: 1/5 --- step 0/500\n","--> epoch: 1/5 --- step 83/500\n","--> epoch: 1/5 --- step 166/500\n","--> epoch: 1/5 --- step 249/500\n","--> epoch: 1/5 --- step 332/500\n","--> epoch: 1/5 --- step 415/500\n","--> epoch: 1/5 --- step 498/500\n","############# Epoch 1: Training End     #############\n","############# Epoch 1: Validation Start   #############\n","--> epoch: 1/5 --- step 0/63\n","--> epoch: 1/5 --- step 10/63\n","--> epoch: 1/5 --- step 20/63\n","--> epoch: 1/5 --- step 30/63\n","--> epoch: 1/5 --- step 40/63\n","--> epoch: 1/5 --- step 50/63\n","--> epoch: 1/5 --- step 60/63\n","############# Epoch 1: Validation End     #############\n","Epoch: 1 \tAvgerage Training Loss: 0.675600 \tAverage Validation Loss: 0.644393\n","Validation loss decreased (inf --> 0.644393).  Saving model ...\n","Model saved to ==> /content/drive/MyDrive/Colab Notebooks/Amplifi Project/Saved Models and Checkpoints/mixed_model_3_Mixed.pt\n","############# Epoch 1  Done   #############\n","\n","############# Epoch 2: Training Start   #############\n","--> epoch: 2/5 --- step 0/500\n","--> epoch: 2/5 --- step 83/500\n","--> epoch: 2/5 --- step 166/500\n","--> epoch: 2/5 --- step 249/500\n","--> epoch: 2/5 --- step 332/500\n","--> epoch: 2/5 --- step 415/500\n","--> epoch: 2/5 --- step 498/500\n","############# Epoch 2: Training End     #############\n","############# Epoch 2: Validation Start   #############\n","--> epoch: 2/5 --- step 0/63\n","--> epoch: 2/5 --- step 10/63\n","--> epoch: 2/5 --- step 20/63\n","--> epoch: 2/5 --- step 30/63\n","--> epoch: 2/5 --- step 40/63\n","--> epoch: 2/5 --- step 50/63\n","--> epoch: 2/5 --- step 60/63\n","############# Epoch 2: Validation End     #############\n","Epoch: 2 \tAvgerage Training Loss: 0.610456 \tAverage Validation Loss: 0.624017\n","Validation loss decreased (0.644393 --> 0.624017).  Saving model ...\n","Model saved to ==> /content/drive/MyDrive/Colab Notebooks/Amplifi Project/Saved Models and Checkpoints/mixed_model_3_Mixed.pt\n","############# Epoch 2  Done   #############\n","\n","############# Epoch 3: Training Start   #############\n","--> epoch: 3/5 --- step 0/500\n","--> epoch: 3/5 --- step 83/500\n","--> epoch: 3/5 --- step 166/500\n","--> epoch: 3/5 --- step 249/500\n","--> epoch: 3/5 --- step 332/500\n","--> epoch: 3/5 --- step 415/500\n","--> epoch: 3/5 --- step 498/500\n","############# Epoch 3: Training End     #############\n","############# Epoch 3: Validation Start   #############\n","--> epoch: 3/5 --- step 0/63\n","--> epoch: 3/5 --- step 10/63\n","--> epoch: 3/5 --- step 20/63\n","--> epoch: 3/5 --- step 30/63\n","--> epoch: 3/5 --- step 40/63\n","--> epoch: 3/5 --- step 50/63\n","--> epoch: 3/5 --- step 60/63\n","############# Epoch 3: Validation End     #############\n","Epoch: 3 \tAvgerage Training Loss: 0.521538 \tAverage Validation Loss: 0.630527\n","############# Epoch 3  Done   #############\n","\n","############# Epoch 4: Training Start   #############\n","--> epoch: 4/5 --- step 0/500\n","--> epoch: 4/5 --- step 83/500\n","--> epoch: 4/5 --- step 166/500\n","--> epoch: 4/5 --- step 249/500\n","--> epoch: 4/5 --- step 332/500\n","--> epoch: 4/5 --- step 415/500\n","--> epoch: 4/5 --- step 498/500\n","############# Epoch 4: Training End     #############\n","############# Epoch 4: Validation Start   #############\n","--> epoch: 4/5 --- step 0/63\n","--> epoch: 4/5 --- step 10/63\n","--> epoch: 4/5 --- step 20/63\n","--> epoch: 4/5 --- step 30/63\n","--> epoch: 4/5 --- step 40/63\n","--> epoch: 4/5 --- step 50/63\n","--> epoch: 4/5 --- step 60/63\n","############# Epoch 4: Validation End     #############\n","Epoch: 4 \tAvgerage Training Loss: 0.388795 \tAverage Validation Loss: 0.682871\n","############# Epoch 4  Done   #############\n","\n","############# Epoch 5: Training Start   #############\n","--> epoch: 5/5 --- step 0/500\n","--> epoch: 5/5 --- step 83/500\n","--> epoch: 5/5 --- step 166/500\n","--> epoch: 5/5 --- step 249/500\n","--> epoch: 5/5 --- step 332/500\n","--> epoch: 5/5 --- step 415/500\n","--> epoch: 5/5 --- step 498/500\n","############# Epoch 5: Training End     #############\n","############# Epoch 5: Validation Start   #############\n","--> epoch: 5/5 --- step 0/63\n","--> epoch: 5/5 --- step 10/63\n","--> epoch: 5/5 --- step 20/63\n","--> epoch: 5/5 --- step 30/63\n","--> epoch: 5/5 --- step 40/63\n","--> epoch: 5/5 --- step 50/63\n","--> epoch: 5/5 --- step 60/63\n","############# Epoch 5: Validation End     #############\n","Epoch: 5 \tAvgerage Training Loss: 0.259316 \tAverage Validation Loss: 0.861221\n","############# Epoch 5  Done   #############\n","\n"]}],"source":["epochs = 5\n","trained_model = train_model(epochs, featurizer, train_loader, val_loader, model, optimizer, destination_folder)"]},{"cell_type":"markdown","metadata":{"id":"pX29LuX5HDas"},"source":["# Testing"]},{"cell_type":"code","source":["tok2id = tokenizer.vocab\n","tok2id['<del>'] = len(tok2id)\n","lexicon_feature_bits = 1\n","featurizer = Featurizer(tok2id, lexicon_feature_bits=lexicon_feature_bits)"],"metadata":{"id":"yZ-TkSBWvGt5","executionInfo":{"status":"ok","timestamp":1663374699705,"user_tz":-60,"elapsed":45,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"cJ-Sp0dfHEYz","outputId":"64c8b329-9923-4f8b-da8f-c86504761817"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Model loaded from <== /content/drive/MyDrive/Colab Notebooks/Amplifi Project/Saved Models and Checkpoints/mixed_model_3.pt\n","accuracy = 70.7366797068709 %\n"]}],"source":["# testing\n","corrects = 0\n","totals = 0\n","\n","test_model = Mixed_Model_3()\n","test_model.to(device)\n","optimizer = torch.optim.Adam(params =  test_model.parameters(), lr=1e-5)\n","destination_folder = \"/content/drive/MyDrive/Colab Notebooks/Amplifi Project/Saved Models and Checkpoints/\"\n","load_checkpoint(destination_folder + '/mixed_model_3_' + dataset + '.pt', test_model, optimizer)\n","\n","with torch.no_grad():\n","  test_model.eval() \n","  for batch_idx, data in enumerate(test_loader, 0): \n","    input_ids = data['input_ids'].to(device, dtype=torch.long)\n","    attention_mask = data['attention_mask'].to(device, dtype=torch.long)\n","    \n","    feats = featurizer.featurize_batch(\n","                data['input_ids'].detach().cpu().numpy(), \n","                data['rel_ids'].detach().cpu().numpy(), \n","                data['pos_ids'].detach().cpu().numpy(), \n","                padded_len=data['input_ids'].shape[1])\n","\n","    feats = torch.tensor(feats.reshape(feats.shape[0],-1)).to(device, dtype = torch.float)\n","    \n","    output = test_model(feats, input_ids, attention_mask)\n","    final_output = torch.sigmoid(output).cpu().detach().numpy().tolist()\n","    pred_class = np.round(final_output)\n","    corrects += np.count_nonzero((data['targets'] - pred_class) == 0.)\n","    totals += len(pred_class)\n","  \n","  # Calculate accuracy of test set\n","  acc = corrects / totals\n","\n","  print(f'accuracy = {acc * 100} %')"]},{"cell_type":"code","source":["# Evaluation Function\n","\n","def evaluate(model, test_loader, threshold=0.5):\n","    y_pred = []\n","    y_true = []\n","\n","    model.eval()\n","    with torch.no_grad():\n","        for data in test_loader:           \n","            labels = data['targets'].to(device)\n","            input_ids = data['input_ids'].to(device, dtype=torch.long)\n","            attention_mask = data['attention_mask'].to(device, dtype=torch.long)\n","\n","            feats = featurizer.featurize_batch(\n","                        data['input_ids'].detach().cpu().numpy(), \n","                        data['rel_ids'].detach().cpu().numpy(), \n","                        data['pos_ids'].detach().cpu().numpy(), \n","                        padded_len=data['input_ids'].shape[1])\n","\n","            feats = torch.tensor(feats.reshape(feats.shape[0],-1)).to(device, dtype = torch.float)\n","            \n","            output = model(feats, input_ids, attention_mask)\n","            output = torch.sigmoid(output).cpu().detach().numpy().tolist()\n","            output = np.round(output)\n","            y_pred.extend(output.tolist())\n","            y_true.extend(labels.tolist())\n","    \n","    print('Classification Report:')\n","    print('remember: 1 = BIASED, 0 = UNBIASED')\n","    print(classification_report(y_true, y_pred, labels=[1,0], digits=4))\n","    \n","    cm = confusion_matrix(y_true, y_pred, labels=[1,0])\n","    ax= plt.subplot()\n","    sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n","\n","    ax.set_title('Confusion Matrix')\n","\n","    ax.set_xlabel('Predicted Labels')\n","    ax.set_ylabel('True Labels')\n","\n","    ax.xaxis.set_ticklabels(['BIASED', 'UNBIASED'])\n","    ax.yaxis.set_ticklabels(['BIASED', 'UNBIASED'])\n","    \n","    \n","best_model = Mixed_Model_3().to(device)\n","optimizer = optim.Adam(best_model.parameters(), lr=1e-5)\n","\n","destination_folder = \"/content/drive/MyDrive/Colab Notebooks/Amplifi Project/Saved Models and Checkpoints\"\n","load_checkpoint(destination_folder + '/mixed_model_3_' + dataset + '.pt', best_model, optimizer)\n","evaluate(best_model, test_loader)"],"metadata":{"id":"0W3ICA4fFadC","colab":{"base_uri":"https://localhost:8080/","height":583},"executionInfo":{"status":"ok","timestamp":1663374727937,"user_tz":-60,"elapsed":28265,"user":{"displayName":"Jo Rossello","userId":"16140766760579671400"}},"outputId":"c6db1dcf-26d2-4faf-f223-b5c95a5e8102"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Model loaded from <== /content/drive/MyDrive/Colab Notebooks/Amplifi Project/Saved Models and Checkpoints/mixed_model_3_Mixed.pt\n","Classification Report:\n","remember: 1 = BIASED, 0 = UNBIASED\n","              precision    recall  f1-score   support\n","\n","           1     0.7352    0.5924    0.6561       525\n","           0     0.6291    0.7642    0.6901       475\n","\n","    accuracy                         0.6740      1000\n","   macro avg     0.6822    0.6783    0.6731      1000\n","weighted avg     0.6848    0.6740    0.6723      1000\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":["0ihgV4BqzGmD","XcLwaiiqAUbf","wxg4JvvNO2QZ","ksTMDIVhAbQi","KRYjD4p5BV5R","m8HK9QreBTz1","EcVTnZdBGXnv","pX29LuX5HDas"],"provenance":[],"authorship_tag":"ABX9TyMe96AZX4uiZWWHIjG+4+0g"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"541861263f704bcb810158fc098adff6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_740a763932ed4423b8d03b88c856d6e6","IPY_MODEL_4396614da47540b3857f656e148eec21","IPY_MODEL_049ddf865425425bb0b0ae2f95ee8524"],"layout":"IPY_MODEL_54e5cebeda5a407bbc893b3acdaf9b60"}},"740a763932ed4423b8d03b88c856d6e6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f84b3b5ca62463f9184d66dbb3cfe49","placeholder":"​","style":"IPY_MODEL_9b8cbc25a9584669924b1b37dfb3a72e","value":""}},"4396614da47540b3857f656e148eec21":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dec18f9dd81f4e3ba0d2df06b1a20435","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c21929cb23fd4afa87ee2bde1aa4a598","value":0}},"049ddf865425425bb0b0ae2f95ee8524":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_15fbfc6c948b4f379def1414a129e707","placeholder":"​","style":"IPY_MODEL_58d7ce73f72c4d3487fac82b4499ccf7","value":" 0/0 [00:00&lt;?, ?it/s]"}},"54e5cebeda5a407bbc893b3acdaf9b60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f84b3b5ca62463f9184d66dbb3cfe49":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b8cbc25a9584669924b1b37dfb3a72e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dec18f9dd81f4e3ba0d2df06b1a20435":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"c21929cb23fd4afa87ee2bde1aa4a598":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"15fbfc6c948b4f379def1414a129e707":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58d7ce73f72c4d3487fac82b4499ccf7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}